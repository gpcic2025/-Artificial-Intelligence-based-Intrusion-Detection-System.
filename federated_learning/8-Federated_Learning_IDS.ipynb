{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1_t398aMYSpL5Z4Goj-LdEve3NmHc_4fB","authorship_tag":"ABX9TyPAzm91a/+YXr/l2hUwv6BR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3H5PtCf9vfl","executionInfo":{"status":"ok","timestamp":1748475794181,"user_tz":-180,"elapsed":17029,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"b8e960de-d4d6-4f72-ee18-805a8d894ac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ”” Using temporary Colab storage for BASE_DIR: /content/federated_ids_ai_project\n","   Data in this path will NOT persist across sessions unless you change it to a Drive path.\n","\n","Project base directory: /content/federated_ids_ai_project\n","Data directory (for client data if loaded from files): /content/federated_ids_ai_project/data\n","Models directory (for saved FL models): /content/federated_ids_ai_project/models\n","Federated Learning outputs directory: /content/federated_ids_ai_project/federated_outputs\n","\n","âœ… Section 1 (Federated Learning - Setup and Configuration) is ready.\n"]}],"source":["import os\n","import sys\n","import json\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import threading\n","import argparse # For command-line argument parsing\n","from datetime import datetime\n","\n","# Imports for machine learning and federated learning components\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","# For TensorFlow models\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model, clone_model\n","from tensorflow.keras.layers import Dense, LSTM, Dropout\n","from tensorflow.keras.optimizers import Adam # Using Adam directly\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# --- ACTION REQUIRED: Mount your Google Drive if you plan to use it for persistent storage ---\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# --- Define project base directory ---\n","# You can change this to a path in your Google Drive, e.g., \"/content/drive/MyDrive/FL_IDS_Project\"\n","# If left as is, it will create a directory in the current Colab session's temporary storage.\n","BASE_DIR = \"/content/federated_ids_ai_project\" # Default path for this federated learning script\n","\n","if \"/content/drive/\" in BASE_DIR:\n","    print(f\"âœ… Using Google Drive path for BASE_DIR: {BASE_DIR}\") # Ensured regular spaces\n","else:\n","    print(f\"ðŸ”” Using temporary Colab storage for BASE_DIR: {BASE_DIR}\") # Ensured regular spaces\n","    print(\"   Data in this path will NOT persist across sessions unless you change it to a Drive path.\") # Ensured regular spaces\n","\n","# Define subdirectories for data, models, and federated learning artifacts\n","DATA_DIR = os.path.join(BASE_DIR, \"data\")\n","MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n","FL_DIR = os.path.join(BASE_DIR, \"federated_outputs\")\n","\n","# Create directories if they don't exist\n","for directory in [BASE_DIR, DATA_DIR, MODEL_DIR, FL_DIR]:\n","    os.makedirs(directory, exist_ok=True)\n","\n","print(f\"\\nProject base directory: {BASE_DIR}\")\n","print(f\"Data directory (for client data if loaded from files): {DATA_DIR}\")\n","print(f\"Models directory (for saved FL models): {MODEL_DIR}\")\n","print(f\"Federated Learning outputs directory: {FL_DIR}\")\n","\n","print(\"\\nâœ… Section 1 (Federated Learning - Setup and Configuration) is ready.\")"]},{"cell_type":"code","source":["#@title ðŸ“± Section 2: Federated Learning -\n","class FederatedClient:\n","    \"\"\"\n","    Represents a client (edge device) in the federated learning system.\n","    Each client has its own local data and model.\n","    \"\"\"\n","\n","    def __init__(self, client_id, data=None, model=None):\n","        self.client_id = client_id\n","        self.data = data # Can be a DataFrame, or will be loaded by load_data\n","        self.model = model # Keras model instance, can be assigned later\n","        self.history = [] # To store training history for this client\n","        print(f\"Client {self.client_id}: Initialized.\")\n","\n","    def load_data(self, data_path=None, partition_identifier=None, total_partitions=1):\n","        \"\"\"\n","        Load data for this client.\n","        If data_path is provided, load from file and take a specific partition.\n","        If self.data was already a DataFrame (e.g., pre-partitioned and passed during init), it's used.\n","\n","        Args:\n","            data_path (str, optional): Path to the full dataset file (e.g., .csv, .json, .jsonl).\n","            partition_identifier (int, optional): An identifier for this client's partition (e.g., client_id).\n","                                                  Used with total_partitions to select a data slice.\n","                                                  Assumes 0-based indexing for partitions.\n","            total_partitions (int, optional): Total number of partitions the dataset should be divided into.\n","        \"\"\"\n","        if data_path and os.path.exists(data_path): # Check if data_path is provided and exists\n","            try:\n","                print(f\"Client {self.client_id}: Attempting to load full dataset from {data_path}...\")\n","                if data_path.endswith('.csv'):\n","                    full_data_df = pd.read_csv(data_path, low_memory=False)\n","                elif data_path.endswith('.json') or data_path.endswith('.jsonl'):\n","                    full_data_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","                else:\n","                    raise ValueError(f\"Unsupported file format for data_path: {data_path}\")\n","\n","                if partition_identifier is not None and total_partitions > 0 and total_partitions <= len(full_data_df):\n","                    if not (0 <= partition_identifier < total_partitions):\n","                        raise ValueError(f\"Client {self.client_id}: partition_identifier ({partition_identifier}) \"\n","                                         f\"must be between 0 and total_partitions-1 ({total_partitions-1}).\")\n","\n","                    num_samples_total = len(full_data_df)\n","                    # Integer division for roughly equal partitions\n","                    samples_per_partition = num_samples_total // total_partitions\n","\n","                    start_idx = partition_identifier * samples_per_partition\n","                    # For the last partition, assign all remaining samples to ensure all data is used\n","                    end_idx = (partition_identifier + 1) * samples_per_partition if partition_identifier < total_partitions - 1 else num_samples_total\n","\n","                    self.data = full_data_df.iloc[start_idx:end_idx].copy()\n","                    print(f\"Client {self.client_id}: Loaded partition {partition_identifier + 1}/{total_partitions} \"\n","                          f\"(indices {start_idx}-{end_idx-1}, {len(self.data)} samples) from {data_path}\")\n","                else: # Use the whole dataset if no valid partitioning info\n","                    self.data = full_data_df\n","                    print(f\"Client {self.client_id}: Loaded {len(self.data)} samples (full dataset) from {data_path}\")\n","                return True\n","\n","            except Exception as e:\n","                print(f\"Client {self.client_id}: Error loading data from path '{data_path}': {e}\")\n","                self.data = None\n","                return False\n","\n","        elif isinstance(self.data, pd.DataFrame): # Data was passed during __init__\n","            print(f\"Client {self.client_id}: Using {len(self.data)} samples from pre-loaded DataFrame.\")\n","            return True\n","        elif self.data is not None: # Data was passed but not a DataFrame\n","             try:\n","                self.data = pd.DataFrame(self.data) # Try to convert\n","                print(f\"Client {self.client_id}: Converted pre-loaded data to DataFrame, {len(self.data)} samples.\")\n","                return True\n","             except Exception as e:\n","                print(f\"Client {self.client_id}: Could not convert pre-loaded data of type {type(self.data)} to DataFrame: {e}\")\n","                self.data = None\n","                return False\n","        else: # No data_path and self.data is None\n","            print(f\"Client {self.client_id}: No data path provided and no pre-loaded data.\")\n","            self.data = None\n","            return False\n","\n","    def preprocess_data(self, feature_columns=None, target_column=None, test_size=0.2, reshape_for_lstm=False):\n","        \"\"\"\n","        Preprocess the client's local data.\n","        This includes feature selection, label encoding, scaling, and splitting.\n","        Returns: (X_train_scaled, X_test_scaled, y_train, y_test, preproc_objects) or None\n","        \"\"\"\n","        if self.data is None or self.data.empty:\n","            print(f\"Client {self.client_id}: No data loaded for preprocessing.\")\n","            return None\n","\n","        try:\n","            df_processed = self.data.copy()\n","            df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n","            df_processed.dropna(inplace=True)\n","\n","            if df_processed.empty:\n","                print(f\"Client {self.client_id}: Data became empty after handling NaNs during preprocessing.\")\n","                return None\n","\n","            if target_column is None:\n","                target_column = df_processed.columns[-1]\n","                print(f\"Client {self.client_id}: Assuming last column '{target_column}' as target.\")\n","\n","            if target_column not in df_processed.columns:\n","                print(f\"Client {self.client_id}: Target column '{target_column}' not found.\")\n","                return None\n","\n","            y = df_processed[target_column]\n","\n","            if feature_columns is None:\n","                X = df_processed.drop(columns=[target_column])\n","                print(f\"Client {self.client_id}: Using all columns except '{target_column}' as features.\")\n","            else:\n","                missing_cols = [col for col in feature_columns if col not in df_processed.columns]\n","                if missing_cols:\n","                    print(f\"Client {self.client_id}: Missing specified feature columns: {missing_cols}\")\n","                    return None\n","                X = df_processed[feature_columns]\n","\n","            used_feature_columns = X.columns.tolist()\n","\n","            # Ensure X contains only numeric data for scaling, or handle non-numeric appropriately\n","            X_numeric = X.select_dtypes(include=np.number)\n","            if X_numeric.shape[1] < X.shape[1]:\n","                non_numeric_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n","                print(f\"Client {self.client_id}: Warning - Dropping non-numeric columns from features: {non_numeric_cols}. \"\n","                      \"These should be encoded if they are intended for use.\")\n","            X = X_numeric # Proceed with only numeric features\n","\n","            if X.empty:\n","                print(f\"Client {self.client_id}: No numeric features available after selection/filtering.\")\n","                return None\n","\n","            label_encoder = LabelEncoder()\n","            y_encoded = label_encoder.fit_transform(y)\n","            num_classes = len(label_encoder.classes_)\n","\n","            # Stratification requires at least 2 samples per class in the smallest split (test set)\n","            # or generally at least n_splits samples per class.\n","            min_samples_per_class_for_stratify = 2 # A common minimum for train_test_split with test_size\n","            class_counts = pd.Series(y_encoded).value_counts()\n","\n","            can_stratify = num_classes >= 2 and all(count >= min_samples_per_class_for_stratify for count in class_counts)\n","\n","            if can_stratify:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id, stratify=y_encoded\n","                )\n","            else:\n","                if num_classes < 2:\n","                    print(f\"Client {self.client_id}: Only {num_classes} unique class(es) in target. Cannot stratify or train effectively.\")\n","                    # If only one class, training is not meaningful\n","                    return None\n","                print(f\"Client {self.client_id}: Cannot stratify due to too few samples in some classes. Splitting without stratification.\")\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id\n","                )\n","\n","            scaler = StandardScaler()\n","            X_train_scaled = scaler.fit_transform(X_train)\n","            X_test_scaled = scaler.transform(X_test)\n","\n","            if reshape_for_lstm:\n","                X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n","                X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n","\n","            preproc_objects = {\n","                'scaler': scaler,\n","                'label_encoder': label_encoder,\n","                'used_feature_columns': used_feature_columns,\n","                'target_column_name': target_column,\n","                'num_classes': num_classes # Number of unique classes found by LabelEncoder\n","            }\n","\n","            print(f\"Client {self.client_id}: Data preprocessed. Train shape: {X_train_scaled.shape}, Test shape: {X_test_scaled.shape}\")\n","            return X_train_scaled, X_test_scaled, y_train, y_test, preproc_objects\n","\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Error during data preprocessing: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            return None\n","\n","# --- Test Block for FederatedClient Data Handling (Optional) ---\n","# This test runs only if the cell is executed directly in Colab\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedClient Data Handling ---\")\n","\n","    # Create dummy data for client\n","    dummy_data_for_client = pd.DataFrame({\n","        'feature1': np.random.rand(100),\n","        'feature2': np.random.rand(100),\n","        'feature3_cat': np.random.choice(['A', 'B', 'C'], 100), # Categorical feature\n","        'feature4_num': np.random.randint(0, 5, 100),\n","        'label': np.random.choice(['Normal', 'Attack_Type1', 'Attack_Type2'], 100) # Multi-class target\n","    })\n","\n","    # DATA_DIR should be defined from Section 1\n","    if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n","        dummy_csv_path = os.path.join(DATA_DIR, \"client_dummy_data.csv\")\n","        dummy_data_for_client.to_csv(dummy_csv_path, index=False)\n","        print(f\"Dummy data saved to {dummy_csv_path}\")\n","\n","        # Test Case 1: Load from path with partitioning\n","        print(\"\\n-- Test Case 1: Load from path with partitioning --\")\n","        client1 = FederatedClient(client_id=1)\n","        # Load 1st partition out of 2\n","        client1.load_data(data_path=dummy_csv_path, partition_identifier=0, total_partitions=2)\n","        if client1.data is not None:\n","            print(f\"Client 1 data shape after load & partition: {client1.data.shape}\")\n","            # Preprocess, assuming last col 'label' is target, and we want LSTM shape\n","            # Explicitly select numeric features for this dummy data, excluding 'feature3_cat' for now\n","            client1_preproc_result = client1.preprocess_data(\n","                feature_columns=['feature1', 'feature2', 'feature4_num'],\n","                target_column='label',\n","                reshape_for_lstm=True\n","            )\n","            if client1_preproc_result:\n","                 print(f\"Client 1 preprocessed train data shape (LSTM): {client1_preproc_result[0].shape}\")\n","                 print(f\"Client 1 preprocessed objects: {client1_preproc_result[4].keys()}\")\n","                 print(f\"Client 1 num_classes from preproc: {client1_preproc_result[4]['num_classes']}\")\n","\n","\n","        # Test Case 2: Load with pre-loaded data (full dummy data)\n","        print(\"\\n-- Test Case 2: Load with pre-loaded data --\")\n","        client2 = FederatedClient(client_id=2, data=dummy_data_for_client.copy()) # Pass a copy\n","        client2.load_data() # Should use the pre-loaded data, already a DataFrame\n","        if client2.data is not None:\n","            print(f\"Client 2 data shape from pre-loaded: {client2.data.shape}\")\n","            # Preprocess for MLP, using default feature selection (all numeric but target)\n","            client2_preproc_result = client2.preprocess_data(target_column='label', reshape_for_lstm=False)\n","            if client2_preproc_result:\n","                 print(f\"Client 2 preprocessed train data shape (MLP): {client2_preproc_result[0].shape}\")\n","                 print(f\"Client 2 preprocessed objects keys: {list(client2_preproc_result[4].keys())}\")\n","                 print(f\"Client 2 target classes by LabelEncoder: {client2_preproc_result[4]['label_encoder'].classes_}\")\n","                 print(f\"Client 2 num_classes from preproc: {client2_preproc_result[4]['num_classes']}\")\n","\n","    else:\n","        print(\"âš ï¸ Skipping FederatedClient data handling test as DATA_DIR is not defined \" \\\n","              \"or accessible (Run Section 1 of Federated Learning script).\")\n","    print(\"\\n--- End of FederatedClient Data Handling Test ---\")\n","\n","print(\"\\nâœ… Section 2 (FederatedClient Class - Part 1: Init & Data) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"je-pKgE2_dPP","executionInfo":{"status":"ok","timestamp":1748475794456,"user_tz":-180,"elapsed":331,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"4e9bec63-dc3f-475a-8544-0c3d3f066935"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedClient Data Handling ---\n","Dummy data saved to /content/federated_ids_ai_project/data/client_dummy_data.csv\n","\n","-- Test Case 1: Load from path with partitioning --\n","Client 1: Initialized.\n","Client 1: Attempting to load full dataset from /content/federated_ids_ai_project/data/client_dummy_data.csv...\n","Client 1: Loaded partition 1/2 (indices 0-49, 50 samples) from /content/federated_ids_ai_project/data/client_dummy_data.csv\n","Client 1 data shape after load & partition: (50, 5)\n","Client 1: Data preprocessed. Train shape: (40, 1, 3), Test shape: (10, 1, 3)\n","Client 1 preprocessed train data shape (LSTM): (40, 1, 3)\n","Client 1 preprocessed objects: dict_keys(['scaler', 'label_encoder', 'used_feature_columns', 'target_column_name', 'num_classes'])\n","Client 1 num_classes from preproc: 3\n","\n","-- Test Case 2: Load with pre-loaded data --\n","Client 2: Initialized.\n","Client 2: Using 100 samples from pre-loaded DataFrame.\n","Client 2 data shape from pre-loaded: (100, 5)\n","Client 2: Using all columns except 'label' as features.\n","Client 2: Warning - Dropping non-numeric columns from features: ['feature3_cat']. These should be encoded if they are intended for use.\n","Client 2: Data preprocessed. Train shape: (80, 3), Test shape: (20, 3)\n","Client 2 preprocessed train data shape (MLP): (80, 3)\n","Client 2 preprocessed objects keys: ['scaler', 'label_encoder', 'used_feature_columns', 'target_column_name', 'num_classes']\n","Client 2 target classes by LabelEncoder: ['Attack_Type1' 'Attack_Type2' 'Normal']\n","Client 2 num_classes from preproc: 3\n","\n","--- End of FederatedClient Data Handling Test ---\n","\n","âœ… Section 2 (FederatedClient Class - Part 1: Init & Data) is ready.\n"]}]},{"cell_type":"code","source":["\n","#@title ðŸ§  Section 3: Federated Learning - FederatedClient Class (Part 2: Model Building & Training)\n","# Imports from Section 1 should still be in effect.\n","# Ensure TensorFlow/Keras components are available.\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, clone_model\n","from tensorflow.keras.layers import Dense, LSTM, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from datetime import datetime\n","\n","class FederatedClient:\n","    \"\"\"\n","    Represents a client (edge device) in the federated learning system.\n","    Each client has its own local data and model.\n","    (Includes methods from Part 1 and adds new methods from Part 2)\n","    \"\"\"\n","\n","    def __init__(self, client_id, data=None, model=None):\n","        self.client_id = client_id\n","        self.data = data\n","        self.model = model\n","        self.history = []\n","        # print(f\"Client {self.client_id}: Initialized.\") # Keep this less verbose for multiple clients\n","\n","    def load_data(self, data_path=None, partition_identifier=None, total_partitions=1):\n","        if data_path and os.path.exists(data_path):\n","            try:\n","                # print(f\"Client {self.client_id}: Attempting to load full dataset from {data_path}...\")\n","                if data_path.endswith('.csv'): full_data_df = pd.read_csv(data_path, low_memory=False)\n","                elif data_path.endswith(('.json', '.jsonl')): full_data_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","                else: raise ValueError(f\"Unsupported file format: {data_path}\")\n","\n","                if partition_identifier is not None and total_partitions > 0 and total_partitions <= len(full_data_df):\n","                    if not (0 <= partition_identifier < total_partitions): raise ValueError(\"partition_identifier out of range.\")\n","                    num_samples_total = len(full_data_df)\n","                    samples_per_partition = num_samples_total // total_partitions\n","                    start_idx = partition_identifier * samples_per_partition\n","                    end_idx = (partition_identifier + 1) * samples_per_partition if partition_identifier < total_partitions - 1 else num_samples_total\n","                    self.data = full_data_df.iloc[start_idx:end_idx].copy()\n","                    # print(f\"Client {self.client_id}: Loaded partition {partition_identifier + 1}/{total_partitions} ({len(self.data)} samples)\")\n","                else:\n","                    self.data = full_data_df\n","                    # print(f\"Client {self.client_id}: Loaded {len(self.data)} samples (full dataset).\")\n","                return True\n","            except Exception as e:\n","                print(f\"Client {self.client_id}: Error loading data from '{data_path}': {e}\"); self.data = None; return False"],"metadata":{"id":"qfXlHzoBAoUn","executionInfo":{"status":"ok","timestamp":1748475794462,"user_tz":-180,"elapsed":4,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","#@title ðŸ§  Section 3: Federated Learning - FederatedClient Class (Part 2: Model Building & Training)\n","# Imports from Section 1 should still be in effect.\n","# Class FederatedClient from Section 2 will be extended here.\n","\n","class FederatedClient:\n","    \"\"\"\n","    Represents a client (edge device) in the federated learning system.\n","    Each client has its own local data and model.\n","    (Includes methods from Part 1 and adds new methods from Part 2)\n","    \"\"\"\n","\n","    def __init__(self, client_id, data=None, model=None):\n","        self.client_id = client_id\n","        self.data = data\n","        self.model = model\n","        self.history = []\n","        # print(f\"Client {self.client_id}: Initialized.\") # Kept less verbose\n","\n","    def load_data(self, data_path=None, partition_identifier=None, total_partitions=1):\n","        if data_path and os.path.exists(data_path):\n","            try:\n","                # print(f\"Client {self.client_id}: Loading from {data_path}...\") # Verbose\n","                if data_path.endswith('.csv'): full_data_df = pd.read_csv(data_path, low_memory=False)\n","                elif data_path.endswith(('.json', '.jsonl')): full_data_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","                else: raise ValueError(f\"Unsupported file format: {data_path}\")\n","\n","                if partition_identifier is not None and total_partitions > 0 and total_partitions <= len(full_data_df):\n","                    if not (0 <= partition_identifier < total_partitions): raise ValueError(\"partition_identifier out of range.\")\n","                    num_samples_total = len(full_data_df)\n","                    samples_per_partition = num_samples_total // total_partitions\n","                    start_idx = partition_identifier * samples_per_partition\n","                    end_idx = (partition_identifier + 1) * samples_per_partition if partition_identifier < total_partitions - 1 else num_samples_total\n","                    self.data = full_data_df.iloc[start_idx:end_idx].copy()\n","                    # print(f\"Client {self.client_id}: Loaded partition {partition_identifier + 1}/{total_partitions} ({len(self.data)} samples)\")\n","                else:\n","                    self.data = full_data_df\n","                    # print(f\"Client {self.client_id}: Loaded {len(self.data)} samples (full dataset).\")\n","                return True\n","            except Exception as e:\n","                print(f\"Client {self.client_id}: Error loading data from '{data_path}': {e}\"); self.data = None; return False\n","        elif isinstance(self.data, pd.DataFrame): return True\n","        elif self.data is not None:\n","             try: self.data = pd.DataFrame(self.data); return True\n","             except Exception as e: print(f\"Client {self.client_id}: Could not convert pre-loaded data: {e}\"); self.data=None; return False\n","        else: self.data = None; return False\n","\n","    def preprocess_data(self, feature_columns=None, target_column=None, test_size=0.2, reshape_for_lstm=False):\n","        if self.data is None or self.data.empty: return None\n","        try:\n","            df_processed = self.data.copy()\n","            df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n","            df_processed.dropna(inplace=True)\n","            if df_processed.empty: return None\n","\n","            if target_column is None: target_column = df_processed.columns[-1]\n","            if target_column not in df_processed.columns: return None\n","            y = df_processed[target_column]\n","\n","            if feature_columns is None: X = df_processed.drop(columns=[target_column])\n","            else:\n","                missing_cols = [col for col in feature_columns if col not in df_processed.columns]\n","                if missing_cols: print(f\"Client {self.client_id}: Missing features: {missing_cols}\"); return None\n","                X = df_processed[feature_columns]\n","\n","            used_feature_columns = X.columns.tolist()\n","            X_numeric = X.select_dtypes(include=np.number)\n","            if X_numeric.shape[1] < X.shape[1]: pass # Non-numeric will be dropped\n","            X = X_numeric\n","            if X.empty: return None\n","\n","            label_encoder = LabelEncoder()\n","            y_encoded = label_encoder.fit_transform(y)\n","            num_classes = len(label_encoder.classes_)\n","\n","            min_samples_per_class_for_stratify = 2\n","            class_counts = pd.Series(y_encoded).value_counts()\n","            can_stratify = num_classes >= 2 and all(count >= min_samples_per_class_for_stratify for count in class_counts)\n","\n","            stratify_option = y_encoded if can_stratify else None\n","            try:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id, stratify=stratify_option\n","                )\n","            except ValueError: # Fallback if stratification fails for any reason\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id\n","                )\n","\n","            scaler = StandardScaler()\n","            X_train_scaled = scaler.fit_transform(X_train)\n","            X_test_scaled = scaler.transform(X_test)\n","\n","            if reshape_for_lstm:\n","                X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n","                X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n","\n","            preproc_objects = {\n","                'scaler': scaler, 'label_encoder': label_encoder,\n","                'used_feature_columns': used_feature_columns,\n","                'target_column_name': target_column, 'num_classes': num_classes\n","            }\n","            # print(f\"Client {self.client_id}: Data preprocessed. Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")\n","            return X_train_scaled, X_test_scaled, y_train, y_test, preproc_objects\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Error preprocessing: {e}\"); import traceback; traceback.print_exc(); return None\n","\n","    # --- New methods for Section 3 ---\n","    def build_lstm_model(self, input_shape, num_classes):\n","        \"\"\"Build an LSTM model for sequence classification.\"\"\"\n","        model = Sequential([\n","            LSTM(64, input_shape=input_shape, return_sequences=True),\n","            Dropout(0.2),\n","            LSTM(32), # return_sequences=False by default for the last LSTM layer before Dense\n","            Dropout(0.2),\n","            Dense(16, activation='relu'), # An intermediate dense layer\n","            Dense(num_classes, activation='softmax') # Softmax for multi-class classification\n","        ])\n","        model.compile(\n","            optimizer=Adam(learning_rate=0.001),\n","            loss='sparse_categorical_crossentropy', # Use for integer labels\n","            metrics=['accuracy']\n","        )\n","        return model\n","\n","    def build_mlp_model(self, input_shape, num_classes):\n","        \"\"\"Build a simple MLP model for classification.\"\"\"\n","        model = Sequential([\n","            Dense(128, activation='relu', input_shape=input_shape),\n","            Dropout(0.3),\n","            Dense(64, activation='relu'),\n","            Dropout(0.2),\n","            Dense(32, activation='relu'),\n","            Dense(num_classes, activation='softmax') # Softmax for multi-class\n","        ])\n","        model.compile(\n","            optimizer=Adam(learning_rate=0.001),\n","            loss='sparse_categorical_crossentropy', # Use for integer labels\n","            metrics=['accuracy']\n","        )\n","        return model\n","\n","    def train_local_model(self, model_type='mlp', epochs=10, batch_size=32, verbose=0, feature_columns=None, target_column=None):\n","        \"\"\"Train the local model on the client's data.\"\"\"\n","        if self.data is None:\n","            print(f\"Client {self.client_id}: No data loaded for training.\")\n","            return None\n","\n","        preproc_result = self.preprocess_data(\n","            feature_columns=feature_columns,\n","            target_column=target_column,\n","            reshape_for_lstm=(model_type.lower() == 'lstm')\n","        )\n","        if preproc_result is None:\n","            print(f\"Client {self.client_id}: Preprocessing failed for training.\")\n","            return None\n","\n","        X_train, X_test, y_train, y_test, preproc_objects = preproc_result\n","        num_classes = preproc_objects['num_classes']\n","\n","        # Ensure there's data to train on\n","        if X_train.shape[0] == 0:\n","            print(f\"Client {self.client_id}: No training data after preprocessing (X_train is empty).\")\n","            return None\n","\n","        if model_type.lower() == 'lstm':\n","            model_input_shape = (X_train.shape[1], X_train.shape[2]) # Should be (1, num_features)\n","            self.model = self.build_lstm_model(model_input_shape, num_classes)\n","        else: # MLP\n","            model_input_shape = (X_train.shape[1],) # (num_features,)\n","            self.model = self.build_mlp_model(model_input_shape, num_classes)\n","\n","        # print(f\"Client {self.client_id}: Training {model_type.upper()} model. Input shape: {model_input_shape}, Classes: {num_classes}.\")\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=0)\n","\n","        history_obj = self.model.fit(\n","            X_train, y_train,\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            validation_data=(X_test, y_test),\n","            callbacks=[early_stopping],\n","            verbose=verbose # Controlled by argument\n","        )\n","\n","        loss, accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n","\n","        train_result_summary = {\n","            'client_id': self.client_id, 'model_type': model_type,\n","            'epochs_run': len(history_obj.history['loss']),\n","            'batch_size': batch_size,\n","            'history': {k: [round(float(val), 4) for val in v] for k, v in history_obj.history.items()}, # Ensure float for JSON\n","            'test_loss': float(loss), 'test_accuracy': float(accuracy),\n","            'timestamp': datetime.now().isoformat()\n","        }\n","        self.history.append(train_result_summary)\n","\n","        print(f\"Client {self.client_id}: Training completed. Test accuracy: {accuracy:.4f}\")\n","        return {\n","            'model_weights': self.model.get_weights(),\n","            'num_samples': X_train.shape[0] + X_test.shape[0], # Total samples processed by client\n","            'preprocessing_details': preproc_objects,\n","            'training_summary': train_result_summary\n","        }\n","\n","# --- Test Block for FederatedClient Model Training (Optional) ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedClient Model Training ---\")\n","    if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n","        dummy_csv_path = os.path.join(DATA_DIR, \"client_dummy_data.csv\")\n","        if not os.path.exists(dummy_csv_path):\n","            dummy_data_for_client = pd.DataFrame({\n","                'feature1': np.random.rand(100), 'feature2': np.random.rand(100),\n","                'feature3_cat': np.random.choice(['A', 'B', 'C'], 100), # Will be dropped by current preprocess\n","                'feature4_num': np.random.randint(0, 5, 100),\n","                'label': np.random.choice(['Normal', 'Attack_Type1', 'Attack_Type2'], 100)\n","            })\n","            dummy_data_for_client.to_csv(dummy_csv_path, index=False)\n","            print(f\"Re-created dummy data at {dummy_csv_path} for test.\")\n","\n","        client3 = FederatedClient(client_id=3) # New client for this test\n","        # Load full dummy data for client3\n","        loaded = client3.load_data(data_path=dummy_csv_path, partition_identifier=0, total_partitions=1)\n","\n","        if loaded and client3.data is not None:\n","            print(f\"\\n-- Training MLP model on Client 3 (Epochs=3, Verbose=1) --\")\n","            numeric_features_for_dummy = ['feature1', 'feature2', 'feature4_num']\n","            mlp_train_results = client3.train_local_model(\n","                model_type='mlp', epochs=3, verbose=1,\n","                feature_columns=numeric_features_for_dummy, target_column='label'\n","            )\n","            if mlp_train_results:\n","                print(f\"Client 3 MLP training summary: Test Accuracy {mlp_train_results['training_summary']['test_accuracy']:.4f}\")\n","\n","            client3.model = None # Reset model to ensure LSTM builds fresh\n","            print(f\"\\n-- Training LSTM model on Client 3 (Epochs=3, Verbose=1) --\")\n","            lstm_train_results = client3.train_local_model(\n","                model_type='lstm', epochs=3, verbose=1,\n","                feature_columns=numeric_features_for_dummy, target_column='label'\n","            )\n","            if lstm_train_results:\n","                print(f\"Client 3 LSTM training summary: Test Accuracy {lstm_train_results['training_summary']['test_accuracy']:.4f}\")\n","        else:\n","            print(\"Client 3 could not load data for model training test.\")\n","    else:\n","        print(\"âš ï¸ Skipping FederatedClient model training test as DATA_DIR not found (Run Section 1).\")\n","    print(\"\\n--- End of FederatedClient Model Training Test ---\")\n","\n","print(\"\\nâœ… Section 3 (FederatedClient Class - Part 2: Model Building & Training) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3OH7dv5Bhnp","executionInfo":{"status":"ok","timestamp":1748475812425,"user_tz":-180,"elapsed":17960,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"d621343c-011a-43ca-9286-11d288a207e3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedClient Model Training ---\n","\n","-- Training MLP model on Client 3 (Epochs=3, Verbose=1) --\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.3500 - loss: 1.1244 - val_accuracy: 0.2500 - val_loss: 1.0937\n","Epoch 2/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.3461 - loss: 1.1167 - val_accuracy: 0.1500 - val_loss: 1.0898\n","Epoch 3/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.3805 - loss: 1.0851 - val_accuracy: 0.2000 - val_loss: 1.0874\n","Client 3: Training completed. Test accuracy: 0.2000\n","Client 3 MLP training summary: Test Accuracy 0.2000\n","\n","-- Training LSTM model on Client 3 (Epochs=3, Verbose=1) --\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - accuracy: 0.3758 - loss: 1.0980 - val_accuracy: 0.3500 - val_loss: 1.0974\n","Epoch 2/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4711 - loss: 1.0950 - val_accuracy: 0.3000 - val_loss: 1.0968\n","Epoch 3/3\n","\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4453 - loss: 1.0939 - val_accuracy: 0.4500 - val_loss: 1.0963\n","Client 3: Training completed. Test accuracy: 0.4500\n","Client 3 LSTM training summary: Test Accuracy 0.4500\n","\n","--- End of FederatedClient Model Training Test ---\n","\n","âœ… Section 3 (FederatedClient Class - Part 2: Model Building & Training) is ready.\n"]}]},{"cell_type":"code","source":["#@title ðŸ’¾ Section 4: Federated Learning - FederatedClient Class (Part 3: Model Management & Evaluation)\n","\n","\n","class FederatedClient:\n","    \"\"\"\n","    Represents a client (edge device) in the federated learning system.\n","    Each client has its own local data and model.\n","    (Includes methods from Part 1 & 2, and adds new methods from Part 3)\n","    \"\"\"\n","\n","    def __init__(self, client_id, data=None, model=None):\n","        self.client_id = client_id\n","        self.data = data\n","        self.model = model\n","        self.history = []\n","        # print(f\"Client {self.client_id}: Initialized.\") # Verbosity controlled\n","\n","    def load_data(self, data_path=None, partition_identifier=None, total_partitions=1):\n","        # This method is from Section 2, included for completeness of the class definition\n","        if data_path and os.path.exists(data_path):\n","            try:\n","                if data_path.endswith('.csv'): full_data_df = pd.read_csv(data_path, low_memory=False)\n","                elif data_path.endswith(('.json', '.jsonl')): full_data_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","                else: raise ValueError(f\"Unsupported file format: {data_path}\")\n","\n","                if partition_identifier is not None and total_partitions > 0 and total_partitions <= len(full_data_df):\n","                    if not (0 <= partition_identifier < total_partitions): raise ValueError(\"partition_identifier out of range.\")\n","                    num_samples_total = len(full_data_df)\n","                    samples_per_partition = num_samples_total // total_partitions\n","                    start_idx = partition_identifier * samples_per_partition\n","                    end_idx = (partition_identifier + 1) * samples_per_partition if partition_identifier < total_partitions - 1 else num_samples_total\n","                    self.data = full_data_df.iloc[start_idx:end_idx].copy()\n","                else:\n","                    self.data = full_data_df\n","                return True\n","            except Exception as e:\n","                print(f\"Client {self.client_id}: Error loading data from '{data_path}': {e}\"); self.data = None; return False\n","        elif isinstance(self.data, pd.DataFrame): return True\n","        elif self.data is not None:\n","             try: self.data = pd.DataFrame(self.data); return True\n","             except Exception as e: print(f\"Client {self.client_id}: Could not convert pre-loaded data: {e}\"); self.data=None; return False\n","        else: self.data = None; return False\n","\n","    def preprocess_data(self, feature_columns=None, target_column=None, test_size=0.2, reshape_for_lstm=False):\n","        # This method is from Section 2, included for completeness\n","        if self.data is None or self.data.empty: return None\n","        try:\n","            df_processed = self.data.copy()\n","            df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n","            df_processed.dropna(inplace=True)\n","            if df_processed.empty: return None\n","\n","            if target_column is None: target_column = df_processed.columns[-1]\n","            if target_column not in df_processed.columns: return None\n","            y = df_processed[target_column]\n","\n","            if feature_columns is None: X = df_processed.drop(columns=[target_column])\n","            else:\n","                missing_cols = [col for col in feature_columns if col not in df_processed.columns]\n","                if missing_cols: print(f\"Client {self.client_id}: Missing features: {missing_cols}\"); return None\n","                X = df_processed[feature_columns]\n","\n","            used_feature_columns = X.columns.tolist()\n","            X_numeric = X.select_dtypes(include=np.number)\n","            if X_numeric.shape[1] < X.shape[1]: pass\n","            X = X_numeric\n","            if X.empty: return None\n","\n","            label_encoder = LabelEncoder()\n","            y_encoded = label_encoder.fit_transform(y)\n","            num_classes = len(label_encoder.classes_)\n","\n","            min_samples_per_class_for_stratify = 2\n","            class_counts = pd.Series(y_encoded).value_counts()\n","            can_stratify = num_classes >= 2 and all(count >= min_samples_per_class_for_stratify for count in class_counts if count >0)\n","\n","            stratify_option = y_encoded if can_stratify else None\n","            if len(X) < 2 :\n","                 print(f\"Client {self.client_id}: Not enough samples ({len(X)}) to perform train/test split.\"); return None\n","\n","            try:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id, stratify=stratify_option\n","                )\n","            except ValueError:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=self.client_id\n","                )\n","\n","            scaler = StandardScaler()\n","            X_train_scaled = scaler.fit_transform(X_train)\n","            if len(X_test) > 0:\n","                 X_test_scaled = scaler.transform(X_test)\n","            else:\n","                 X_test_scaled = np.array([])\n","\n","            if reshape_for_lstm:\n","                X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n","                if len(X_test_scaled) > 0:\n","                     X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n","\n","            preproc_objects = {'scaler': scaler, 'label_encoder': label_encoder, 'used_feature_columns': used_feature_columns, 'target_column_name': target_column, 'num_classes': num_classes}\n","            return X_train_scaled, X_test_scaled, y_train, y_test, preproc_objects\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Error preprocessing: {e}\"); import traceback; traceback.print_exc(); return None\n","\n","    def build_lstm_model(self, input_shape, num_classes):\n","        # This method is from Section 3, included for completeness\n","        model = Sequential([\n","            LSTM(64, input_shape=input_shape, return_sequences=True), Dropout(0.2),\n","            LSTM(32), Dropout(0.2), Dense(16, activation='relu'),\n","            Dense(num_classes, activation='softmax')])\n","        model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    def build_mlp_model(self, input_shape, num_classes):\n","        # This method is from Section 3, included for completeness\n","        model = Sequential([\n","            Dense(128, activation='relu', input_shape=input_shape), Dropout(0.3),\n","            Dense(64, activation='relu'), Dropout(0.2), Dense(32, activation='relu'),\n","            Dense(num_classes, activation='softmax')])\n","        model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    def train_local_model(self, model_type='mlp', epochs=10, batch_size=32, verbose=0, feature_columns=None, target_column=None):\n","        # This method is from Section 3, included for completeness\n","        if self.data is None: return None\n","        preproc_result = self.preprocess_data(feature_columns, target_column, reshape_for_lstm=(model_type.lower() == 'lstm'))\n","        if preproc_result is None: return None\n","        X_train, X_test, y_train, y_test, preproc_objects = preproc_result\n","        num_classes = preproc_objects['num_classes']\n","        if X_train.shape[0] == 0: return None\n","\n","        if model_type.lower() == 'lstm':\n","            model_input_shape = (X_train.shape[1], X_train.shape[2])\n","            self.model = self.build_lstm_model(model_input_shape, num_classes)\n","        else:\n","            model_input_shape = (X_train.shape[1],)\n","            self.model = self.build_mlp_model(model_input_shape, num_classes)\n","\n","        validation_data_tuple = (X_test, y_test) if len(X_test) > 0 else None\n","        early_stopping = EarlyStopping(monitor='val_loss' if validation_data_tuple else 'loss', patience=5, restore_best_weights=True, verbose=0)\n","        history_obj = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data_tuple, callbacks=[early_stopping], verbose=verbose)\n","\n","        test_loss, test_accuracy = (0.0,0.0)\n","        if validation_data_tuple :\n","             test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n","\n","        train_summary = {'client_id':self.client_id, 'model_type':model_type, 'epochs_run':len(history_obj.history['loss']), 'batch_size':batch_size, 'history':{k:[round(float(v),4) for v in val_list] for k,val_list in history_obj.history.items()}, 'test_loss':float(test_loss), 'test_accuracy':float(test_accuracy), 'timestamp':datetime.now().isoformat()}\n","        self.history.append(train_summary)\n","        print(f\"Client {self.client_id}: Training completed. Test accuracy: {test_accuracy:.4f}\")\n","        return {'model_weights': self.model.get_weights(), 'num_samples': X_train.shape[0] + (X_test.shape[0] if len(X_test)>0 else 0) , 'preprocessing_details': preproc_objects, 'training_summary': train_summary}\n","\n","    # --- New methods for Section 4 ---\n","    def update_model(self, model_weights):\n","        \"\"\"Update the local model with new weights.\"\"\"\n","        if self.model is None:\n","            print(f\"Client {self.client_id}: No local model initialized to update.\")\n","            return False\n","        try:\n","            self.model.set_weights(model_weights)\n","            return True\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Error updating model weights: {e}\")\n","            return False\n","\n","    def get_model_weights(self):\n","        \"\"\"Get the weights of the local model.\"\"\"\n","        if self.model is None:\n","            print(f\"Client {self.client_id}: No model available to get weights from.\")\n","            return None\n","        return self.model.get_weights()\n","\n","    def evaluate_model(self, X_test_external=None, y_test_external=None, preproc_objects_external=None):\n","        \"\"\"Evaluate the local model.\"\"\"\n","        if self.model is None:\n","            print(f\"Client {self.client_id}: No model to evaluate.\")\n","            return None\n","\n","        X_test_eval, y_test_eval = None, None\n","\n","        if X_test_external is not None and y_test_external is not None:\n","            X_test_eval, y_test_eval = X_test_external, y_test_external\n","            if self.model.layers[0].__class__.__name__ == 'LSTM' and len(X_test_eval.shape) == 2: # Check if model is LSTM by first layer type\n","                 X_test_eval = X_test_eval.reshape(X_test_eval.shape[0], 1, X_test_eval.shape[1])\n","        else:\n","            if not self.history:\n","                print(f\"Client {self.client_id}: No training history and no external test data provided.\")\n","                return None\n","            last_train_summary = self.history[-1]\n","            print(f\"Client {self.client_id}: Reporting test accuracy from last local training: {last_train_summary['test_accuracy']:.4f}\")\n","            return {\n","                'client_id': self.client_id, 'loss': last_train_summary['test_loss'],\n","                'accuracy': last_train_summary['test_accuracy'], 'timestamp': datetime.now().isoformat(),\n","                'note': 'Metrics from last local training validation split.'}\n","\n","        if X_test_eval is None or y_test_eval is None or (isinstance(X_test_eval, np.ndarray) and X_test_eval.size == 0):\n","            print(f\"Client {self.client_id}: No test data available for evaluation.\")\n","            return None\n","\n","        loss, accuracy = self.model.evaluate(X_test_eval, y_test_eval, verbose=0)\n","        y_pred_probs = self.model.predict(X_test_eval, verbose=0)\n","        y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","\n","        report_dict = {}; conf_matrix_list = []\n","        try:\n","            unique_true_labels = np.unique(y_test_eval)\n","            unique_pred_labels = np.unique(y_pred_classes)\n","            all_labels = np.union1d(unique_true_labels, unique_pred_labels) # Get all unique labels present in either\n","\n","            report_dict = classification_report(y_test_eval, y_pred_classes, labels=all_labels if len(all_labels)>0 else None, output_dict=True, zero_division=0)\n","            conf_matrix_list = confusion_matrix(y_test_eval, y_pred_classes, labels=all_labels if len(all_labels)>0 else None).tolist()\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Could not generate full classification report/confusion matrix: {e}\")\n","\n","        eval_result = {\n","            'client_id': self.client_id, 'loss': float(loss), 'accuracy': float(accuracy),\n","            'classification_report': report_dict, 'confusion_matrix': conf_matrix_list,\n","            'timestamp': datetime.now().isoformat()}\n","        return eval_result\n","\n","    def save_model(self, path=None):\n","        \"\"\"Save the local model to a file.\"\"\"\n","        if self.model is None: print(f\"Client {self.client_id}: No model to save.\"); return None\n","        if path is None:\n","            path = os.path.join(FL_DIR if 'FL_DIR' in globals() else \".\", f\"client_{self.client_id}_model.h5\")\n","        try:\n","            self.model.save(path)\n","            print(f\"Client {self.client_id}: Model saved to {path}\")\n","            return path\n","        except Exception as e: print(f\"Client {self.client_id}: Error saving model: {e}\"); return None\n","\n","    def load_model(self, path):\n","        \"\"\"Load a model from a file. Overwrites existing self.model.\"\"\"\n","        try:\n","            self.model = tf.keras.models.load_model(path)\n","            print(f\"Client {self.client_id}: Model loaded from {path}\")\n","            return True\n","        except Exception as e: print(f\"Client {self.client_id}: Error loading model from {path}: {e}\"); return False\n","\n","# --- Test Block for FederatedClient Model Management (Optional) ---\n","# Corrected Indentation and typo for this block\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedClient Model Management ---\")\n","    if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR) and \\\n","       'FL_DIR' in globals() and os.path.exists(FL_DIR):\n","\n","        dummy_csv_path = os.path.join(DATA_DIR, \"client_dummy_data.csv\")\n","        if not os.path.exists(dummy_csv_path):\n","            pd.DataFrame({\n","                'feature1': np.random.rand(40),\n","                'feature2': np.random.rand(40),\n","                'feature4_num': np.random.randint(0,5,40),\n","                'label': np.random.choice(['Normal', 'Attack_Type1'], 40)\n","            }).to_csv(dummy_csv_path, index=False)\n","            print(f\"Created/Re-created dummy data for test: {dummy_csv_path}\")\n","\n","        client4 = FederatedClient(client_id=4)\n","        loaded = client4.load_data(data_path=dummy_csv_path)\n","\n","        if loaded and client4.data is not None:\n","            print(\"\\n-- Training a model on Client 4 to test save/load/evaluate --\")\n","            dummy_numeric_features = ['feature1', 'feature2', 'feature4_num']\n","            train_results_c4 = client4.train_local_model(\n","                model_type='mlp', epochs=1, verbose=0,\n","                feature_columns=dummy_numeric_features, target_column='label'\n","            )\n","\n","            if train_results_c4 and client4.model:\n","                print(f\"Client 4 trained. Accuracy on its test split: {train_results_c4['training_summary']['test_accuracy']:.4f}\")\n","\n","                saved_path = client4.save_model()\n","                if saved_path and os.path.exists(saved_path):\n","                    client_new_load = FederatedClient(client_id=40)\n","                    loaded_successfully = client_new_load.load_model(saved_path)\n","\n","                    if loaded_successfully and client_new_load.model:\n","                        print(\"Model loaded into new client instance (client40) successfully.\")\n","\n","                        # Re-preprocess data for client4 to get its X_test, y_test for evaluation by client40\n","                        c4_preproc_result = client4.preprocess_data(\n","                            feature_columns=dummy_numeric_features, target_column='label', reshape_for_lstm=False # Assuming MLP for this test\n","                        )\n","                        if c4_preproc_result:\n","                            _, c4_X_test, _, c4_y_test, _ = c4_preproc_result\n","                            if c4_X_test is not None and c4_y_test is not None and len(c4_X_test) > 0 :\n","                                eval_res_loaded_model = client_new_load.evaluate_model(X_test_external=c4_X_test, y_test_external=c4_y_test)\n","                                if eval_res_loaded_model:\n","                                    print(f\"Evaluation of loaded model on Client 40 (using Client 4's test data): Accuracy {eval_res_loaded_model['accuracy']:.4f}\")\n","                            else:\n","                                print(\"Could not get Client 4's test data for evaluating loaded model on Client 40.\")\n","                        else:\n","                            print(\"Failed to preprocess data for Client 4 to get test set for evaluation.\")\n","\n","\n","                weights_c4 = client4.get_model_weights()\n","                if weights_c4:\n","                    client_for_weights_test = FederatedClient(client_id=41)\n","                    num_feats_c4 = len(train_results_c4['preprocessing_details']['used_feature_columns'])\n","                    num_classes_c4 = train_results_c4['preprocessing_details']['num_classes']\n","                    client_for_weights_test.model = client_for_weights_test.build_mlp_model(input_shape=(num_feats_c4,), num_classes=num_classes_c4)\n","\n","                    updated = client_for_weights_test.update_model(weights_c4)\n","                    print(f\"Weights updated on client_for_weights_test (client 41): {updated}\")\n","                    if updated and c4_preproc_result: # Use already preprocessed data if available\n","                         _, c4_X_test_for_weights, _, c4_y_test_for_weights, _ = c4_preproc_result\n","                         if c4_X_test_for_weights is not None and c4_y_test_for_weights is not None and len(c4_X_test_for_weights) > 0:\n","                              eval_res_weights = client_for_weights_test.evaluate_model(X_test_external=c4_X_test_for_weights, y_test_external=c4_y_test_for_weights) # Corrected variable name\n","                              if eval_res_weights:\n","                                   print(f\"Evaluation of weights-updated model on Client 41: Accuracy {eval_res_weights['accuracy']:.4f}\")\n","                         else:\n","                              print(\"Could not get Client 4's test data for evaluating weights-updated model on Client 41.\")\n","            else:\n","                print(\"Client 4 model training failed, skipping further tests.\")\n","        else:\n","            print(\"Client 4 could not load data for model management tests.\")\n","    else:\n","        print(\"âš ï¸ Skipping FederatedClient model management test as DATA_DIR or FL_DIR not found (Run Section 1).\")\n","    print(\"\\n--- End of FederatedClient Model Management Test ---\")\n","\n","print(\"\\nâœ… Section 4 (FederatedClient Class - Part 3: Model Management & Evaluation) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6b4JFETCQny","executionInfo":{"status":"ok","timestamp":1748475816549,"user_tz":-180,"elapsed":4121,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"2a0dd966-bd93-44af-8b2b-31d6b4b90d71"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedClient Model Management ---\n","\n","-- Training a model on Client 4 to test save/load/evaluate --\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Client 4: Training completed. Test accuracy: 0.4500\n","Client 4 trained. Accuracy on its test split: 0.4500\n","Client 4: Model saved to /content/federated_ids_ai_project/federated_outputs/client_4_model.h5\n","Client 40: Model loaded from /content/federated_ids_ai_project/federated_outputs/client_4_model.h5\n","Model loaded into new client instance (client40) successfully.\n","Evaluation of loaded model on Client 40 (using Client 4's test data): Accuracy 0.4500\n","Weights updated on client_for_weights_test (client 41): True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7fece42c79c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluation of weights-updated model on Client 41: Accuracy 0.4500\n","\n","--- End of FederatedClient Model Management Test ---\n","\n","âœ… Section 4 (FederatedClient Class - Part 3: Model Management & Evaluation) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient class from Sections 2, 3, 4 should be defined.\n","# Ensure all necessary modules like os, np, pd, LabelEncoder, StandardScaler, train_test_split,\n","# Adam, Sequential, LSTM, Dense, Dropout, EarlyStopping, datetime are available from previous cells or Section 1.\n","\n","class FederatedClient:\n","    \"\"\"\n","    Represents a client (edge device) in the federated learning system.\n","    Each client has its own local data and model.\n","    (Includes methods from Part 1, 2, 3 and this correction)\n","    \"\"\"\n","\n","    def __init__(self, client_id, data=None, model=None):\n","        self.client_id = client_id\n","        self.data = data\n","        self.model = model\n","        self.history = []\n","        # print(f\"Client {self.client_id}: Initialized.\")\n","\n","    def load_data(self, data_path=None, partition_identifier=None, total_partitions=1):\n","        if data_path and os.path.exists(data_path):\n","            try:\n","                if data_path.endswith('.csv'): full_data_df = pd.read_csv(data_path, low_memory=False)\n","                elif data_path.endswith(('.json', '.jsonl')): full_data_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","                else: raise ValueError(f\"Unsupported file format: {data_path}\")\n","\n","                if partition_identifier is not None and total_partitions > 0 and total_partitions <= len(full_data_df):\n","                    if not (0 <= partition_identifier < total_partitions): raise ValueError(\"partition_identifier out of range.\")\n","                    num_samples_total = len(full_data_df)\n","                    samples_per_partition = num_samples_total // total_partitions\n","                    start_idx = partition_identifier * samples_per_partition\n","                    end_idx = (partition_identifier + 1) * samples_per_partition if partition_identifier < total_partitions - 1 else num_samples_total\n","                    self.data = full_data_df.iloc[start_idx:end_idx].copy()\n","                else:\n","                    self.data = full_data_df\n","                return True\n","            except Exception as e:\n","                print(f\"Client {self.client_id}: Error loading data from '{data_path}': {e}\"); self.data = None; return False\n","        elif isinstance(self.data, pd.DataFrame): return True\n","        elif self.data is not None:\n","             try: self.data = pd.DataFrame(self.data); return True\n","             except Exception as e: print(f\"Client {self.client_id}: Could not convert pre-loaded data: {e}\"); self.data=None; return False\n","        else: self.data = None; return False\n","\n","    def preprocess_data(self, feature_columns=None, target_column=None, test_size=0.2, reshape_for_lstm=False):\n","        if self.data is None or self.data.empty: return None\n","        try:\n","            df_processed = self.data.copy()\n","            df_processed.replace([np.inf, -np.inf], np.nan, inplace=True)\n","            df_processed.dropna(inplace=True)\n","            if df_processed.empty: return None\n","\n","            if target_column is None: target_column = df_processed.columns[-1]\n","            if target_column not in df_processed.columns: return None\n","            y = df_processed[target_column]\n","\n","            if feature_columns is None: X = df_processed.drop(columns=[target_column])\n","            else:\n","                missing_cols = [col for col in feature_columns if col not in df_processed.columns]\n","                if missing_cols: print(f\"Client {self.client_id}: Missing features: {missing_cols}\"); return None\n","                X = df_processed[feature_columns]\n","\n","            used_feature_columns = X.columns.tolist()\n","            X_numeric = X.select_dtypes(include=np.number)\n","            if X_numeric.shape[1] < X.shape[1]: pass\n","            X = X_numeric\n","            if X.empty: return None\n","\n","            label_encoder = LabelEncoder()\n","            y_encoded = label_encoder.fit_transform(y)\n","            num_classes = len(label_encoder.classes_)\n","\n","            # --- CORRECTED random_state ---\n","            # Use a hash of the client_id or a fixed integer for reproducibility if client_id is string\n","            client_seed = hash(str(self.client_id)) % (2**32 -1) # Ensure it's within integer limits for random_state\n","\n","            min_samples_per_class_for_stratify = 2\n","            class_counts = pd.Series(y_encoded).value_counts()\n","            can_stratify = num_classes >= 2 and all(count >= min_samples_per_class_for_stratify for count in class_counts if count >0)\n","\n","            stratify_option = y_encoded if can_stratify else None\n","            if len(X) < 2 :\n","                 print(f\"Client {self.client_id}: Not enough samples ({len(X)}) to perform train/test split.\"); return None\n","\n","            try:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=client_seed, stratify=stratify_option # Use client_seed\n","                )\n","            except ValueError:\n","                X_train, X_test, y_train, y_test = train_test_split(\n","                    X, y_encoded, test_size=test_size, random_state=client_seed # Use client_seed\n","                )\n","\n","            scaler = StandardScaler()\n","            X_train_scaled = scaler.fit_transform(X_train)\n","            if len(X_test) > 0:\n","                 X_test_scaled = scaler.transform(X_test)\n","            else:\n","                 X_test_scaled = np.array([])\n","\n","            if reshape_for_lstm:\n","                X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n","                if len(X_test_scaled) > 0:\n","                     X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n","\n","            preproc_objects = {'scaler': scaler, 'label_encoder': label_encoder, 'used_feature_columns': used_feature_columns, 'target_column_name': target_column, 'num_classes': num_classes}\n","            return X_train_scaled, X_test_scaled, y_train, y_test, preproc_objects\n","        except Exception as e:\n","            print(f\"Client {self.client_id}: Error preprocessing: {e}\"); import traceback; traceback.print_exc(); return None\n","\n","    def build_lstm_model(self, input_shape, num_classes):\n","        model = Sequential([\n","            LSTM(64, input_shape=input_shape, return_sequences=True), Dropout(0.2),\n","            LSTM(32), Dropout(0.2), Dense(16, activation='relu'),\n","            Dense(num_classes, activation='softmax')])\n","        model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    def build_mlp_model(self, input_shape, num_classes):\n","        model = Sequential([\n","            Dense(128, activation='relu', input_shape=input_shape), Dropout(0.3),\n","            Dense(64, activation='relu'), Dropout(0.2), Dense(32, activation='relu'),\n","            Dense(num_classes, activation='softmax')])\n","        model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    def train_local_model(self, model_type='mlp', epochs=10, batch_size=32, verbose=0, feature_columns=None, target_column=None):\n","        if self.data is None: return None\n","        preproc_result = self.preprocess_data(feature_columns, target_column, reshape_for_lstm=(model_type.lower() == 'lstm'))\n","        if preproc_result is None: return None\n","        X_train, X_test, y_train, y_test, preproc_objects = preproc_result\n","        num_classes = preproc_objects['num_classes']\n","        if X_train.shape[0] == 0: return None\n","\n","        if model_type.lower() == 'lstm':\n","            model_input_shape = (X_train.shape[1], X_train.shape[2])\n","            self.model = self.build_lstm_model(model_input_shape, num_classes)\n","        else:\n","            model_input_shape = (X_train.shape[1],)\n","            self.model = self.build_mlp_model(model_input_shape, num_classes)\n","\n","        validation_data_tuple = (X_test, y_test) if len(X_test) > 0 else None\n","        early_stopping = EarlyStopping(monitor='val_loss' if validation_data_tuple else 'loss', patience=5, restore_best_weights=True, verbose=0)\n","        history_obj = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data_tuple, callbacks=[early_stopping], verbose=verbose)\n","\n","        test_loss, test_accuracy = (0.0,0.0)\n","        if validation_data_tuple :\n","             test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)\n","\n","        train_summary = {'client_id':self.client_id, 'model_type':model_type, 'epochs_run':len(history_obj.history['loss']), 'batch_size':batch_size, 'history':{k:[round(float(v),4) for v in val_list] for k,val_list in history_obj.history.items()}, 'test_loss':float(test_loss), 'test_accuracy':float(test_accuracy), 'timestamp':datetime.now().isoformat()}\n","        self.history.append(train_summary)\n","        # print(f\"Client {self.client_id}: Training completed. Test accuracy: {test_accuracy:.4f}\") # Verbose\n","        return {'model_weights': self.model.get_weights(), 'num_samples': X_train.shape[0] + (X_test.shape[0] if len(X_test)>0 else 0) , 'preprocessing_details': preproc_objects, 'training_summary': train_summary}\n","\n","    def update_model(self, model_weights):\n","        if self.model is None: print(f\"Client {self.client_id}: No model to update.\"); return False\n","        try: self.model.set_weights(model_weights); return True\n","        except Exception as e: print(f\"Client {self.client_id}: Error updating weights: {e}\"); return False\n","\n","    def get_model_weights(self):\n","        if self.model is None: print(f\"Client {self.client_id}: No model for weights.\"); return None\n","        return self.model.get_weights()\n","\n","    def evaluate_model(self, X_test_external=None, y_test_external=None, preproc_objects_external=None):\n","        if self.model is None: print(f\"Client {self.client_id}: No model to evaluate.\"); return None\n","        X_test_eval, y_test_eval = X_test_external, y_test_external\n","        if X_test_eval is None or y_test_eval is None :\n","            if not self.history: print(f\"Client {self.client_id}: No history & no external data.\"); return None\n","            last_sum = self.history[-1]\n","            # print(f\"Client {self.client_id}: Reporting from last local training: Acc {last_sum['test_accuracy']:.4f}\") # Verbose\n","            return {'client_id':self.client_id, 'loss':last_sum['test_loss'], 'accuracy':last_sum['test_accuracy'], 'timestamp':datetime.now().isoformat(), 'note':'Metrics from last local training validation.'}\n","\n","        if self.model.layers[0].__class__.__name__ == 'LSTM' and len(X_test_eval.shape) == 2:\n","            X_test_eval = X_test_eval.reshape(X_test_eval.shape[0], 1, X_test_eval.shape[1])\n","        if isinstance(X_test_eval, np.ndarray) and X_test_eval.size == 0: print(f\"Client {self.client_id}: No test data.\"); return None\n","\n","        loss, accuracy = self.model.evaluate(X_test_eval, y_test_eval, verbose=0)\n","        y_pred_probs = self.model.predict(X_test_eval, verbose=0); y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","        report_dict={}; conf_matrix_list=[]\n","        try:\n","            labels = np.union1d(np.unique(y_test_eval), np.unique(y_pred_classes))\n","            report_dict = classification_report(y_test_eval,y_pred_classes,labels=labels if len(labels)>0 else None,output_dict=True,zero_division=0)\n","            conf_matrix_list = confusion_matrix(y_test_eval,y_pred_classes,labels=labels if len(labels)>0 else None).tolist()\n","        except Exception as e: print(f\"Client {self.client_id}: Could not gen report/matrix: {e}\")\n","        return {'client_id':self.client_id, 'loss':float(loss), 'accuracy':float(accuracy), 'classification_report':report_dict, 'confusion_matrix':conf_matrix_list, 'timestamp':datetime.now().isoformat()}\n","\n","    def save_model(self, path=None):\n","        if self.model is None: print(f\"Client {self.client_id}: No model to save.\"); return None\n","        if path is None: path = os.path.join(FL_DIR if 'FL_DIR' in globals() else \".\", f\"client_{self.client_id}_model.h5\")\n","        try: self.model.save(path); print(f\"Client {self.client_id}: Model saved to {path}\"); return path\n","        except Exception as e: print(f\"Client {self.client_id}: Error saving model: {e}\"); return None\n","\n","    def load_model(self, path):\n","        try: self.model = tf.keras.models.load_model(path); print(f\"Client {self.client_id}: Model loaded from {path}\"); return True\n","        except Exception as e: print(f\"Client {self.client_id}: Error loading model from {path}: {e}\"); return False\n","\n","class FederatedServer:\n","    \"\"\"\n","    Represents the central server in the federated learning system.\n","    Coordinates the training process across multiple clients.\n","    (Definition for Part 1 of the Server)\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.clients = {}\n","        self.global_model = None\n","        self.global_model_type = None\n","        self.global_model_input_shape = None\n","        self.global_model_num_classes = None\n","        self.aggregation_history = []\n","        print(\"Federated Server: Initialized.\")\n","\n","    def add_client(self, client):\n","        if not isinstance(client, FederatedClient):\n","            print(f\"Error: Attempted to add an object that is not a FederatedClient instance.\")\n","            return\n","        if client.client_id in self.clients:\n","            print(f\"Server: Client {client.client_id} already registered.\")\n","        else:\n","            self.clients[client.client_id] = client\n","            print(f\"Server: Added client {client.client_id}.\")\n","\n","    def remove_client(self, client_id):\n","        if client_id in self.clients:\n","            del self.clients[client_id]\n","            print(f\"Server: Removed client {client_id}.\")\n","            return True\n","        else:\n","            print(f\"Server: Client {client_id} not found.\")\n","            return False\n","\n","    def initialize_global_model(self, model_type='mlp', input_shape=None, num_classes=None, client_for_shape_details=None):\n","        self.global_model_type = model_type.lower()\n","\n","        if input_shape is None or num_classes is None:\n","            if client_for_shape_details and client_for_shape_details.data is not None:\n","                # print(f\"Server: Inferring model shape from client {client_for_shape_details.client_id}...\") # Verbose\n","                # Attempt to get feature names robustly\n","                temp_feature_columns = None\n","                if hasattr(client_for_shape_details.data, 'columns'):\n","                    temp_data_cols = client_for_shape_details.data.columns.tolist()\n","                    if 'label' in temp_data_cols: # Assuming 'label' is a common target name\n","                        temp_feature_columns = [col for col in temp_data_cols if col != 'label' and pd.api.types.is_numeric_dtype(client_for_shape_details.data[col])]\n","                    elif len(temp_data_cols) > 1:\n","                        temp_feature_columns = [col for col in temp_data_cols[:-1] if pd.api.types.is_numeric_dtype(client_for_shape_details.data[col])]\n","\n","                preproc_result = client_for_shape_details.preprocess_data(\n","                    feature_columns=temp_feature_columns,\n","                    reshape_for_lstm=(self.global_model_type == 'lstm')\n","                )\n","                if preproc_result:\n","                    X_train_sample, _, _, _, preproc_objects = preproc_result\n","                    if input_shape is None:\n","                        input_shape = (X_train_sample.shape[1], X_train_sample.shape[2]) if self.global_model_type == 'lstm' else (X_train_sample.shape[1],)\n","                    if num_classes is None:\n","                        num_classes = preproc_objects['num_classes']\n","                    # print(f\"Server: Inferred input_shape={input_shape}, num_classes={num_classes}.\") # Verbose\n","                else:\n","                    # print(\"Server: Failed to infer from client data. Using defaults.\") # Verbose\n","                    pass # Will fall through to defaults\n","            # else:\n","                # print(\"Server: No client data for shape inference. Using defaults.\") # Verbose\n","\n","        if input_shape is None: input_shape = (1, 10) if self.global_model_type == 'lstm' else (10,)\n","        if num_classes is None: num_classes = 2\n","\n","        self.global_model_input_shape = input_shape\n","        self.global_model_num_classes = num_classes\n","\n","        temp_client_for_build = FederatedClient(client_id=\"server_model_builder_temp\")\n","        if self.global_model_type == 'lstm':\n","            self.global_model = temp_client_for_build.build_lstm_model(input_shape, num_classes)\n","        else:\n","            self.global_model = temp_client_for_build.build_mlp_model(input_shape, num_classes)\n","        del temp_client_for_build\n","\n","        print(f\"Server: Initialized global {self.global_model_type.upper()} model.\")\n","        # self.global_model.summary() # Can be verbose\n","\n","# --- Test Block for FederatedServer (Part 1: Init & Client Management) ---\n","# This test runs only if the cell is executed directly in Colab\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedServer (Part 1) ---\")\n","\n","    dummy_csv_path_server_test = None\n","    if 'DATA_DIR' in globals() and os.path.exists(DATA_DIR):\n","        dummy_csv_path_server_test = os.path.join(DATA_DIR, \"server_client_dummy_data.csv\")\n","        if not os.path.exists(dummy_csv_path_server_test):\n","            pd.DataFrame({\n","                'f1_numeric': np.random.rand(50),\n","                'f2_numeric': np.random.rand(50),\n","                'target_label': np.random.choice(['ClassA', 'ClassB'], 50) # Changed target column name for clarity\n","            }).to_csv(dummy_csv_path_server_test, index=False)\n","            print(f\"Created dummy data for server test: {dummy_csv_path_server_test}\")\n","    else:\n","        print(\"âš ï¸ DATA_DIR not found, cannot create dummy data for server test.\")\n","\n","    server = FederatedServer()\n","    client_A = None # Initialize to None\n","\n","    if dummy_csv_path_server_test:\n","        client_A = FederatedClient(client_id=\"client_A_for_server_test\")\n","        client_A.load_data(data_path=dummy_csv_path_server_test, partition_identifier=0, total_partitions=1) # Load full dummy data\n","\n","    client_B = FederatedClient(client_id=\"client_B_for_server_test\")\n","\n","    if client_A: server.add_client(client_A)\n","    server.add_client(client_B)\n","\n","    print(f\"Server has {len(server.clients)} clients registered.\")\n","\n","    print(\"\\n-- Initializing Global MLP Model (inferring from client_A if possible) --\")\n","    server.initialize_global_model(model_type='mlp', client_for_shape_details=client_A) # Pass client_A object\n","    if server.global_model:\n","        print(\"Global MLP Model Initialized by Server.\")\n","        server.global_model.summary() # Print summary to verify shape\n","\n","    server.remove_client(\"client_B_for_server_test\")\n","    print(f\"Server has {len(server.clients)} clients after removal.\")\n","\n","    print(\"\\n--- End of FederatedServer (Part 1) Test ---\")\n","\n","print(\"\\nâœ… Section 5 (FederatedServer Class - Part 1: Init & Client Management) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"id":"S6yHRbt3DcP5","executionInfo":{"status":"ok","timestamp":1748475816720,"user_tz":-180,"elapsed":144,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"5bf847ad-9ee2-4e24-9381-e41d252a9fda"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedServer (Part 1) ---\n","Created dummy data for server test: /content/federated_ids_ai_project/data/server_client_dummy_data.csv\n","Federated Server: Initialized.\n","Server: Added client client_A_for_server_test.\n","Server: Added client client_B_for_server_test.\n","Server has 2 clients registered.\n","\n","-- Initializing Global MLP Model (inferring from client_A if possible) --\n","Server: Initialized global MLP model.\n","Global MLP Model Initialized by Server.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_4\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚             \u001b[38;5;34m384\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚           \u001b[38;5;34m8,256\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  â”‚           \u001b[38;5;34m2,080\u001b[0m â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   â”‚              \u001b[38;5;34m66\u001b[0m â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n","â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n","â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n","â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n","â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n","â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> â”‚\n","â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,786\u001b[0m (42.13 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,786</span> (42.13 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,786\u001b[0m (42.13 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,786</span> (42.13 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Server: Removed client client_B_for_server_test.\n","Server has 1 clients after removal.\n","\n","--- End of FederatedServer (Part 1) Test ---\n","\n","âœ… Section 5 (FederatedServer Class - Part 1: Init & Client Management) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient class (all parts) and FederatedServer class (Part 1) should be defined.\n","\n","class FederatedServer:\n","    \"\"\"\n","    Represents the central server in the federated learning system.\n","    Coordinates the training process across multiple clients.\n","    (Includes methods from Part 1 and adds new methods from Part 2)\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.clients = {}\n","        self.global_model = None\n","        self.global_model_type = None\n","        self.global_model_input_shape = None\n","        self.global_model_num_classes = None\n","        self.aggregation_history = []\n","        # print(\"Federated Server: Initialized.\") # Verbosity controlled\n","\n","    def add_client(self, client):\n","        if not isinstance(client, FederatedClient): return\n","        if client.client_id in self.clients: return\n","        self.clients[client.client_id] = client\n","        # print(f\"Server: Added client {client.client_id}.\")\n","\n","    def remove_client(self, client_id):\n","        if client_id in self.clients:\n","            del self.clients[client_id]; return True\n","        return False\n","\n","    def initialize_global_model(self, model_type='mlp', input_shape=None, num_classes=None, client_for_shape_details=None):\n","        self.global_model_type = model_type.lower()\n","        final_input_shape = input_shape\n","        final_num_classes = num_classes\n","\n","        if final_input_shape is None or final_num_classes is None:\n","            if client_for_shape_details and client_for_shape_details.data is not None:\n","                # print(f\"Server: Inferring model shape from client {client_for_shape_details.client_id}...\")\n","                temp_feature_columns = None\n","                if hasattr(client_for_shape_details.data, 'columns'):\n","                    temp_data_cols = client_for_shape_details.data.columns.tolist()\n","                    # Attempt to find a 'label' or 'target' column, then numeric features\n","                    potential_target_col = None\n","                    if 'label' in temp_data_cols: potential_target_col = 'label'\n","                    elif 'target' in temp_data_cols: potential_target_col = 'target'\n","                    # If no specific target, assume last for preprocessing, but features are numeric only.\n","\n","                    temp_df_numeric_cols = client_for_shape_details.data.select_dtypes(include=np.number).columns.tolist()\n","                    if potential_target_col and potential_target_col in temp_df_numeric_cols : # if target is numeric and selected\n","                         temp_feature_columns = [col for col in temp_df_numeric_cols if col != potential_target_col]\n","                    elif temp_df_numeric_cols: # if target is not numeric or not in numeric, take all numeric as features\n","                         temp_feature_columns = temp_df_numeric_cols\n","\n","                preproc_result = client_for_shape_details.preprocess_data(\n","                    feature_columns=temp_feature_columns,\n","                    target_column=potential_target_col, # Pass potential target\n","                    reshape_for_lstm=(self.global_model_type == 'lstm')\n","                )\n","                if preproc_result:\n","                    X_train_sample, _, _, _, preproc_objects = preproc_result\n","                    if final_input_shape is None:\n","                        final_input_shape = (X_train_sample.shape[1], X_train_sample.shape[2]) if self.global_model_type == 'lstm' else (X_train_sample.shape[1],)\n","                    if final_num_classes is None:\n","                        final_num_classes = preproc_objects['num_classes']\n","                    # print(f\"Server: Inferred input_shape={final_input_shape}, num_classes={final_num_classes}.\")\n","\n","        if final_input_shape is None: final_input_shape = (1, 10) if self.global_model_type == 'lstm' else (10,)\n","        if final_num_classes is None: final_num_classes = 2\n","\n","        self.global_model_input_shape = final_input_shape\n","        self.global_model_num_classes = final_num_classes\n","\n","        temp_client_for_build = FederatedClient(client_id=\"server_model_builder_temp\")\n","        if self.global_model_type == 'lstm':\n","            self.global_model = temp_client_for_build.build_lstm_model(self.global_model_input_shape, self.global_model_num_classes)\n","        else:\n","            self.global_model = temp_client_for_build.build_mlp_model(self.global_model_input_shape, self.global_model_num_classes)\n","        del temp_client_for_build\n","\n","        print(f\"Server: Initialized global {self.global_model_type.upper()} model (Input: {self.global_model_input_shape}, Classes: {self.global_model_num_classes}).\")\n","        # self.global_model.summary()\n","\n","\n","    # --- New methods for Section 6 ---\n","    def federated_averaging(self, client_model_weights_list, client_data_sizes=None):\n","        \"\"\"\n","        Perform federated averaging (FedAvg) on a list of client model weights.\n","\n","        Args:\n","            client_model_weights_list (list): A list where each element is the weights\n","                                             (list of numpy arrays) from a client's model.\n","            client_data_sizes (list, optional): A list of integers representing the number\n","                                                of data samples each client used for training.\n","                                                If None, equal weighting is applied.\n","        Returns:\n","            list: The new global model weights (averaged).\n","        \"\"\"\n","        if not client_model_weights_list:\n","            print(\"Server: No client weights provided for averaging.\")\n","            return None\n","\n","        # Initialize sum of weights with zeros, matching the structure of the first client's weights\n","        avg_weights = [np.zeros_like(layer_weights) for layer_weights in client_model_weights_list[0]]\n","\n","        total_data_size = 0\n","        if client_data_sizes:\n","            if len(client_model_weights_list) != len(client_data_sizes):\n","                print(\"Server: Mismatch between number of client weights and data sizes. Using equal weighting.\")\n","                client_data_sizes = None # Fallback to equal weighting\n","            else:\n","                total_data_size = sum(client_data_sizes)\n","\n","        if total_data_size == 0 or client_data_sizes is None: # Handles equal weighting or empty data sizes\n","            print(\"Server: Using equal weighting for federated averaging.\")\n","            # Equal weighting\n","            num_clients_with_weights = len(client_model_weights_list)\n","            for client_weights in client_model_weights_list:\n","                for i, layer_weights in enumerate(client_weights):\n","                    avg_weights[i] += layer_weights / num_clients_with_weights\n","        else:\n","            # Weighted averaging based on data size\n","            print(f\"Server: Using weighted averaging based on data sizes (total samples: {total_data_size}).\")\n","            for idx, client_weights in enumerate(client_model_weights_list):\n","                weight_factor = client_data_sizes[idx] / total_data_size\n","                for i, layer_weights in enumerate(client_weights):\n","                    avg_weights[i] += layer_weights * weight_factor\n","\n","        print(\"Server: Federated averaging completed.\")\n","        return avg_weights\n","\n","    def train_round(self, round_number, num_selected_clients=None, epochs_per_client=5, batch_size_per_client=32):\n","        \"\"\"\n","        Conducts a single round of federated training.\n","        1. Selects a subset of available clients.\n","        2. Sends the current global model weights to these clients.\n","        3. Clients train the model on their local data.\n","        4. Server collects updated model weights from clients.\n","        5. Server aggregates these weights (e.g., FedAvg) to update the global model.\n","        \"\"\"\n","        if self.global_model is None:\n","            print(\"Server: Global model not initialized. Cannot start training round.\")\n","            return None\n","        if not self.clients:\n","            print(\"Server: No clients registered. Cannot start training round.\")\n","            return None\n","\n","        # Select clients for this round\n","        available_client_ids = list(self.clients.keys())\n","        if not available_client_ids:\n","            print(\"Server: No available clients for this round.\")\n","            return None\n","\n","        if num_selected_clients is None:\n","            num_selected_clients = len(available_client_ids) # Use all available clients\n","\n","        selected_client_ids = random.sample(\n","            available_client_ids,\n","            min(num_selected_clients, len(available_client_ids)) # Ensure not to select more than available\n","        )\n","\n","        if not selected_client_ids:\n","            print(\"Server: No clients were selected for this training round.\")\n","            return None\n","\n","        print(f\"\\n--- Server: Starting Federated Training Round {round_number} ---\")\n","        print(f\"Server: Selected {len(selected_client_ids)} clients for this round: {selected_client_ids}\")\n","\n","        current_global_weights = self.global_model.get_weights()\n","        collected_client_weights = []\n","        client_data_sizes_for_round = []\n","        successful_clients_this_round = []\n","\n","        for client_id in selected_client_ids:\n","            client = self.clients[client_id]\n","            print(f\"Server: Training client {client.client_id}...\")\n","\n","            # Ensure client has a model structure compatible with global model\n","            # If client has no model, or if model type/shape mis-match, re-initialize from global\n","            if client.model is None or \\\n","               client.model.layers[0].input_shape[1:] != self.global_model_input_shape or \\\n","               client.model.layers[-1].output_shape[-1] != self.global_model_num_classes:\n","                print(f\"Client {client.client_id}: Model structure mismatch or not initialized. Rebuilding from global specs.\")\n","                temp_builder_client = FederatedClient(client_id=\"temp_builder\") # Use dummy for build methods\n","                if self.global_model_type == 'lstm':\n","                    client.model = temp_builder_client.build_lstm_model(self.global_model_input_shape, self.global_model_num_classes)\n","                else:\n","                    client.model = temp_builder_client.build_mlp_model(self.global_model_input_shape, self.global_model_num_classes)\n","                del temp_builder_client\n","\n","            client.update_model(current_global_weights) # Send global model to client\n","\n","            # Client trains locally\n","            # Assuming client data is already loaded. Feature/target columns need to be consistent.\n","            # For this simulation, let's assume standard feature/target column names if not specified.\n","            training_result = client.train_local_model(\n","                model_type=self.global_model_type,\n","                epochs=epochs_per_client,\n","                batch_size=batch_size_per_client,\n","                verbose=0 # Keep client training quiet for server logs\n","            )\n","\n","            if training_result and 'model_weights' in training_result:\n","                collected_client_weights.append(training_result['model_weights'])\n","                client_data_sizes_for_round.append(training_result['num_samples'])\n","                successful_clients_this_round.append(client_id)\n","                print(f\"Client {client.client_id}: Training successful. Accuracy: {training_result['training_summary']['test_accuracy']:.4f}\")\n","            else:\n","                print(f\"Client {client.client_id}: Training failed or returned no weights.\")\n","\n","        if not collected_client_weights:\n","            print(\"Server: No weights collected from clients in this round. Global model not updated.\")\n","            return {'round': round_number, 'status': 'failed_no_weights', 'successful_clients': []}\n","\n","        # Aggregate weights (Federated Averaging)\n","        new_global_weights = self.federated_averaging(collected_client_weights, client_data_sizes_for_round)\n","        if new_global_weights:\n","            self.global_model.set_weights(new_global_weights)\n","            print(\"Server: Global model updated with aggregated weights.\")\n","\n","        round_summary = {\n","            'round': round_number,\n","            'status': 'completed',\n","            'num_selected_clients': len(selected_client_ids),\n","            'successful_clients': successful_clients_this_round,\n","            'client_data_sizes': client_data_sizes_for_round\n","        }\n","        self.aggregation_history.append(round_summary)\n","        return round_summary\n","\n","# --- Test Block for FederatedServer (Part 2: Training Round) ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedServer (Part 2: Training Round) ---\")\n","\n","    # Ensure DATA_DIR and FL_DIR are available from Section 1\n","    if 'DATA_DIR' not in globals() or not os.path.exists(DATA_DIR) or \\\n","       'FL_DIR' not in globals() or not os.path.exists(FL_DIR):\n","        print(\"âš ï¸ DATA_DIR or FL_DIR not found. Skipping training round test. Run Section 1 first.\")\n","    else:\n","        # Re-create server and clients for a clean test\n","        server_test_part2 = FederatedServer()\n","\n","        # Create dummy data for clients if it doesn't exist\n","        dummy_data_paths = []\n","        num_test_clients = 3\n","        for i in range(num_test_clients):\n","            client_data_path = os.path.join(DATA_DIR, f\"client_{i}_data_part2.csv\")\n","            dummy_data_paths.append(client_data_path)\n","            if not os.path.exists(client_data_path):\n","                pd.DataFrame({\n","                    'f1': np.random.rand(100 + i*20), # Varying data sizes\n","                    'f2': np.random.rand(100 + i*20),\n","                    'label': np.random.choice(['Class0', 'Class1'], 100 + i*20)\n","                }).to_csv(client_data_path, index=False)\n","                print(f\"Created dummy data for client {i} at {client_data_path}\")\n","\n","        # Add clients\n","        client_objects_for_test = []\n","        for i in range(num_test_clients):\n","            client = FederatedClient(client_id=f\"client_train_test_{i}\")\n","            client.load_data(data_path=dummy_data_paths[i]) # Load entire dummy file for each\n","            server_test_part2.add_client(client)\n","            client_objects_for_test.append(client)\n","\n","        if client_objects_for_test and client_objects_for_test[0].data is not None:\n","            print(\"\\n-- Initializing Global MLP Model for Round Test --\")\n","            server_test_part2.initialize_global_model(\n","                model_type='mlp',\n","                client_for_shape_details=client_objects_for_test[0] # Use first client for shape\n","            )\n","\n","            if server_test_part2.global_model:\n","                print(\"\\n-- Running one round of Federated Training --\")\n","                # Use specific feature/target names for dummy data\n","                round_1_results = server_test_part2.train_round(\n","                    round_number=1,\n","                    num_selected_clients=2, # Select 2 out of 3 clients\n","                    epochs_per_client=2,    # Short epochs\n","                    batch_size_per_client=16\n","                )\n","                if round_1_results:\n","                    print(f\"Round 1 summary: {round_1_results}\")\n","            else:\n","                print(\"Global model not initialized, cannot run training round.\")\n","        else:\n","            print(\"Failed to load data for client_objects_for_test[0], cannot initialize global model for round test.\")\n","\n","    print(\"\\n--- End of FederatedServer (Part 2) Test ---\")\n","\n","print(\"\\nâœ… Section 6 (FederatedServer Class - Part 2: Federated Averaging & Training Round) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dU_S9MxMEG4e","executionInfo":{"status":"ok","timestamp":1748475822513,"user_tz":-180,"elapsed":5794,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"d39738ef-f95e-4e4e-c5e2-e6d4c677c508"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedServer (Part 2: Training Round) ---\n","Created dummy data for client 0 at /content/federated_ids_ai_project/data/client_0_data_part2.csv\n","Created dummy data for client 1 at /content/federated_ids_ai_project/data/client_1_data_part2.csv\n","Created dummy data for client 2 at /content/federated_ids_ai_project/data/client_2_data_part2.csv\n","\n","-- Initializing Global MLP Model for Round Test --\n","Server: Initialized global MLP model (Input: (2,), Classes: 2).\n","\n","-- Running one round of Federated Training --\n","\n","--- Server: Starting Federated Training Round 1 ---\n","Server: Selected 2 clients for this round: ['client_train_test_0', 'client_train_test_2']\n","Server: Training client client_train_test_0...\n","Client client_train_test_0: Model structure mismatch or not initialized. Rebuilding from global specs.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:6 out of the last 18 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x7fece419bb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Client client_train_test_0: Training successful. Accuracy: 0.4500\n","Server: Training client client_train_test_2...\n","Client client_train_test_2: Model structure mismatch or not initialized. Rebuilding from global specs.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Client client_train_test_2: Training successful. Accuracy: 0.4286\n","Server: Using weighted averaging based on data sizes (total samples: 240).\n","Server: Federated averaging completed.\n","Server: Global model updated with aggregated weights.\n","Round 1 summary: {'round': 1, 'status': 'completed', 'num_selected_clients': 2, 'successful_clients': ['client_train_test_0', 'client_train_test_2'], 'client_data_sizes': [100, 140]}\n","\n","--- End of FederatedServer (Part 2) Test ---\n","\n","âœ… Section 6 (FederatedServer Class - Part 2: Federated Averaging & Training Round) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient class (all parts) and FederatedServer class (Parts 1 & 2) should be defined.\n","\n","class FederatedServer:\n","    \"\"\"\n","    Represents the central server in the federated learning system.\n","    Coordinates the training process across multiple clients.\n","    (Includes methods from Part 1 & 2, and adds new methods from Part 3)\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.clients = {}\n","        self.global_model = None\n","        self.global_model_type = None\n","        self.global_model_input_shape = None\n","        self.global_model_num_classes = None\n","        self.aggregation_history = []\n","        # print(\"Federated Server: Initialized.\")\n","\n","    def add_client(self, client):\n","        if not isinstance(client, FederatedClient): return\n","        if client.client_id in self.clients: return\n","        self.clients[client.client_id] = client\n","        # print(f\"Server: Added client {client.client_id}.\")\n","\n","    def remove_client(self, client_id):\n","        if client_id in self.clients:\n","            del self.clients[client_id]; return True\n","        return False\n","\n","    def initialize_global_model(self, model_type='mlp', input_shape=None, num_classes=None, client_for_shape_details=None):\n","        self.global_model_type = model_type.lower()\n","        final_input_shape = input_shape\n","        final_num_classes = num_classes\n","\n","        if final_input_shape is None or final_num_classes is None:\n","            if client_for_shape_details and client_for_shape_details.data is not None:\n","                temp_feature_columns = None\n","                if hasattr(client_for_shape_details.data, 'columns'):\n","                    temp_data_cols = client_for_shape_details.data.columns.tolist()\n","                    potential_target_col = None\n","                    if 'label' in temp_data_cols: potential_target_col = 'label'\n","                    elif 'target' in temp_data_cols: potential_target_col = 'target'\n","\n","                    temp_df_numeric_cols = client_for_shape_details.data.select_dtypes(include=np.number).columns.tolist()\n","                    if potential_target_col and potential_target_col in temp_df_numeric_cols :\n","                         temp_feature_columns = [col for col in temp_df_numeric_cols if col != potential_target_col]\n","                    elif temp_df_numeric_cols:\n","                         temp_feature_columns = temp_df_numeric_cols\n","\n","                preproc_result = client_for_shape_details.preprocess_data(\n","                    feature_columns=temp_feature_columns,\n","                    target_column=potential_target_col,\n","                    reshape_for_lstm=(self.global_model_type == 'lstm')\n","                )\n","                if preproc_result:\n","                    X_train_sample, _, _, _, preproc_objects = preproc_result\n","                    if final_input_shape is None:\n","                        final_input_shape = (X_train_sample.shape[1], X_train_sample.shape[2]) if self.global_model_type == 'lstm' else (X_train_sample.shape[1],)\n","                    if final_num_classes is None:\n","                        final_num_classes = preproc_objects['num_classes']\n","\n","        if final_input_shape is None: final_input_shape = (1, 10) if self.global_model_type == 'lstm' else (10,)\n","        if final_num_classes is None: final_num_classes = 2\n","\n","        self.global_model_input_shape = final_input_shape\n","        self.global_model_num_classes = final_num_classes\n","\n","        temp_client_for_build = FederatedClient(client_id=\"server_model_builder_temp\")\n","        if self.global_model_type == 'lstm':\n","            self.global_model = temp_client_for_build.build_lstm_model(self.global_model_input_shape, self.global_model_num_classes)\n","        else:\n","            self.global_model = temp_client_for_build.build_mlp_model(self.global_model_input_shape, self.global_model_num_classes)\n","        del temp_client_for_build\n","\n","        # print(f\"Server: Initialized global {self.global_model_type.upper()} model (Input: {self.global_model_input_shape}, Classes: {self.global_model_num_classes}).\")\n","\n","\n","    def federated_averaging(self, client_model_weights_list, client_data_sizes=None):\n","        if not client_model_weights_list: return None\n","        avg_weights = [np.zeros_like(w) for w in client_model_weights_list[0]]\n","        total_data_size = 0\n","        if client_data_sizes:\n","            if len(client_model_weights_list) != len(client_data_sizes): client_data_sizes = None\n","            else: total_data_size = sum(client_data_sizes)\n","\n","        if total_data_size == 0 or client_data_sizes is None:\n","            num_clients_with_weights = len(client_model_weights_list)\n","            for client_weights in client_model_weights_list:\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights / num_clients_with_weights\n","        else:\n","            for idx, client_weights in enumerate(client_model_weights_list):\n","                weight_factor = client_data_sizes[idx] / total_data_size\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights * weight_factor\n","        return avg_weights\n","\n","    def train_round(self, round_number, num_selected_clients=None, epochs_per_client=5, batch_size_per_client=32):\n","        if self.global_model is None or not self.clients: return None\n","        available_client_ids = list(self.clients.keys())\n","        if not available_client_ids: return None\n","        if num_selected_clients is None: num_selected_clients = len(available_client_ids)\n","        selected_client_ids = random.sample(available_client_ids, min(num_selected_clients, len(available_client_ids)))\n","        if not selected_client_ids: return None\n","\n","        print(f\"\\n--- Server: Starting FL Round {round_number} with {len(selected_client_ids)} clients: {selected_client_ids} ---\")\n","        current_global_weights = self.global_model.get_weights()\n","        collected_client_weights, client_data_sizes_for_round, successful_clients_this_round = [], [], []\n","\n","        for client_id in selected_client_ids:\n","            client = self.clients[client_id]\n","            # print(f\"Server: Training client {client.client_id}...\") # Verbose\n","            if client.model is None or \\\n","               client.model.layers[0].input_shape[1:] != self.global_model_input_shape or \\\n","               client.model.layers[-1].output_shape[-1] != self.global_model_num_classes:\n","                temp_builder = FederatedClient(client_id=\"temp\")\n","                client.model = temp_builder.build_lstm_model(self.global_model_input_shape, self.global_model_num_classes) if self.global_model_type == 'lstm' \\\n","                    else temp_builder.build_mlp_model(self.global_model_input_shape, self.global_model_num_classes)\n","                del temp_builder\n","            client.update_model(current_global_weights)\n","\n","            training_result = client.train_local_model(model_type=self.global_model_type, epochs=epochs_per_client, batch_size=batch_size_per_client, verbose=0)\n","            if training_result and 'model_weights' in training_result:\n","                collected_client_weights.append(training_result['model_weights'])\n","                client_data_sizes_for_round.append(training_result['num_samples'])\n","                successful_clients_this_round.append(client_id)\n","                # print(f\"Client {client.client_id}: Train OK. Acc: {training_result['training_summary']['test_accuracy']:.4f}\") # Verbose\n","            # else: print(f\"Client {client.client_id}: Training failed.\") # Verbose\n","\n","        if not collected_client_weights: print(\"Server: No weights from clients this round.\"); return {'round':round_number, 'status':'failed_no_weights', 'successful_clients':[]}\n","\n","        new_global_weights = self.federated_averaging(collected_client_weights, client_data_sizes_for_round)\n","        if new_global_weights: self.global_model.set_weights(new_global_weights); print(\"Server: Global model updated via FedAvg.\")\n","\n","        round_summary = {'round':round_number, 'status':'completed', 'num_selected':len(selected_client_ids), 'successful_clients':successful_clients_this_round, 'client_data_sizes':client_data_sizes_for_round}\n","        self.aggregation_history.append(round_summary)\n","        return round_summary\n","\n","    # --- New methods for Section 7 ---\n","    def evaluate_global_model(self, X_test_global, y_test_global):\n","        \"\"\"\n","        Evaluate the current global model on a provided global test dataset.\n","        \"\"\"\n","        if self.global_model is None:\n","            print(\"Server: Global model not initialized. Cannot evaluate.\")\n","            return None\n","\n","        if X_test_global is None or y_test_global is None or (isinstance(X_test_global, np.ndarray) and X_test_global.size == 0):\n","            print(\"Server: No global test data provided for evaluation.\")\n","            return None\n","\n","        # Reshape X_test_global if the global model is LSTM and data is not already shaped\n","        X_test_to_eval = X_test_global\n","        if self.global_model_type == 'lstm' and len(X_test_to_eval.shape) == 2:\n","            X_test_to_eval = X_test_to_eval.reshape(X_test_to_eval.shape[0], 1, X_test_to_eval.shape[1])\n","\n","        print(f\"Server: Evaluating global model on provided test set (shape: {X_test_to_eval.shape})...\")\n","        loss, accuracy = self.global_model.evaluate(X_test_to_eval, y_test_global, verbose=0)\n","\n","        y_pred_probs = self.global_model.predict(X_test_to_eval, verbose=0)\n","        y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","\n","        report_dict = {}; conf_matrix_list = []\n","        try:\n","            labels = np.union1d(np.unique(y_test_global), np.unique(y_pred_classes))\n","            report_dict = classification_report(y_test_global, y_pred_classes, labels=labels if len(labels)>0 else None, output_dict=True, zero_division=0)\n","            conf_matrix_list = confusion_matrix(y_test_global, y_pred_classes, labels=labels if len(labels)>0 else None).tolist()\n","        except Exception as e:\n","            print(f\"Server: Could not generate full report/matrix for global model: {e}\")\n","\n","        eval_result = {\n","            'timestamp': datetime.now().isoformat(),\n","            'loss': float(loss), 'accuracy': float(accuracy),\n","            'classification_report': report_dict,\n","            'confusion_matrix': conf_matrix_list\n","        }\n","        print(f\"Server: Global Model Evaluation - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n","        return eval_result\n","\n","    def save_global_model(self, path=None):\n","        \"\"\"Save the global model to a file.\"\"\"\n","        if self.global_model is None: print(\"Server: No global model to save.\"); return None\n","        if path is None:\n","            # MODEL_DIR should be defined from Section 1\n","            path = os.path.join(MODEL_DIR if 'MODEL_DIR' in globals() else \".\",\n","                                f\"fl_global_{self.global_model_type}_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\")\n","        try:\n","            self.global_model.save(path)\n","            print(f\"Server: Global model saved to {path}\")\n","            return path\n","        except Exception as e: print(f\"Server: Error saving global model: {e}\"); return None\n","\n","    def load_global_model(self, path):\n","        \"\"\"Load a global model from a file.\"\"\"\n","        try:\n","            self.global_model = tf.keras.models.load_model(path) # Use tf.keras.models.load_model\n","            # Infer type, shape, classes if possible (might need to be stored alongside model)\n","            self.global_model_type = 'lstm' if any(isinstance(layer, LSTM) for layer in self.global_model.layers) else 'mlp'\n","            self.global_model_input_shape = self.global_model.layers[0].input_shape[1:] # Exclude batch size\n","            self.global_model_num_classes = self.global_model.layers[-1].output_shape[-1]\n","            print(f\"Server: Global model loaded from {path} (Type: {self.global_model_type}, Input: {self.global_model_input_shape}, Classes: {self.global_model_num_classes})\")\n","            return True\n","        except Exception as e: print(f\"Server: Error loading global model from {path}: {e}\"); return False\n","\n","    def save_history(self, path=None):\n","        \"\"\"Save the aggregation history to a file.\"\"\"\n","        if not self.aggregation_history: print(\"Server: No aggregation history to save.\"); return None\n","        if path is None:\n","            # FL_DIR should be defined from Section 1\n","            path = os.path.join(FL_DIR if 'FL_DIR' in globals() else \".\",\n","                                f\"fl_aggregation_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n","        try:\n","            with open(path, 'w') as f: json.dump(self.aggregation_history, f, indent=2)\n","            print(f\"Server: Aggregation history saved to {path}\")\n","            return path\n","        except Exception as e: print(f\"Server: Error saving aggregation history: {e}\"); return None\n","\n","# --- Test Block for FederatedServer (Part 3: Evaluation & Saving) ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\")\n","\n","    if 'DATA_DIR' not in globals() or not os.path.exists(DATA_DIR) or \\\n","       'MODEL_DIR' not in globals() or not os.path.exists(MODEL_DIR) or \\\n","       'FL_DIR' not in globals() or not os.path.exists(FL_DIR):\n","        print(\"âš ï¸ DATA_DIR, MODEL_DIR or FL_DIR not found. Skipping test. Run Section 1 first.\")\n","    elif 'FederatedClient' not in globals() or 'FederatedServer' not in globals():\n","        print(\"âš ï¸ FederatedClient or FederatedServer class not defined. Run previous sections.\")\n","    else:\n","        # Use existing server_test_part2 if available from Section 6 test, or create new\n","        if 'server_test_part2' in locals() and isinstance(server_test_part2, FederatedServer) and server_test_part2.global_model:\n","            server_eval_test = server_test_part2\n","            print(\"Using server instance from Part 2 test.\")\n","        else:\n","            print(\"Creating new server instance for Part 3 test.\")\n","            server_eval_test = FederatedServer()\n","            # Setup a client and initialize global model if server_test_part2 was not run/successful\n","            client_for_init = FederatedClient(client_id=\"init_client_for_eval_test\")\n","            dummy_data_path_eval = os.path.join(DATA_DIR, \"server_client_dummy_data.csv\") # From previous test\n","            if os.path.exists(dummy_data_path_eval):\n","                client_for_init.load_data(data_path=dummy_data_path_eval)\n","                server_eval_test.initialize_global_model(model_type='mlp', client_for_shape_details=client_for_init)\n","            else: # Fallback if dummy data is missing\n","                server_eval_test.initialize_global_model(model_type='mlp', input_shape=(10,), num_classes=2)\n","\n","\n","        if server_eval_test.global_model:\n","            print(\"\\n-- Testing Global Model Evaluation --\")\n","            # Create some dummy global test data\n","            # Shape should match server_eval_test.global_model_input_shape\n","            eval_input_shape = server_eval_test.global_model_input_shape\n","            num_eval_samples = 50\n","\n","            if server_eval_test.global_model_type == 'lstm':\n","                # eval_input_shape is (timesteps, features) e.g. (1, 10)\n","                X_global_test = np.random.rand(num_eval_samples, eval_input_shape[0], eval_input_shape[1])\n","            else: # MLP\n","                # eval_input_shape is (features,) e.g. (10,)\n","                X_global_test = np.random.rand(num_eval_samples, eval_input_shape[0])\n","\n","            y_global_test = np.random.randint(0, server_eval_test.global_model_num_classes, num_eval_samples)\n","\n","            eval_results = server_eval_test.evaluate_global_model(X_global_test, y_global_test)\n","            if eval_results:\n","                print(f\"Global model evaluation result (on random data): Accuracy {eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save/Load Global Model --\")\n","            saved_model_path = server_eval_test.save_global_model()\n","            if saved_model_path and os.path.exists(saved_model_path):\n","                server_new_load_test = FederatedServer()\n","                loaded = server_new_load_test.load_global_model(saved_model_path)\n","                if loaded and server_new_load_test.global_model:\n","                    print(\"Global model loaded into new server instance successfully.\")\n","                    # Quick eval to check if loaded model works\n","                    re_eval_results = server_new_load_test.evaluate_global_model(X_global_test, y_global_test)\n","                    if re_eval_results:\n","                         print(f\"Re-evaluation of loaded global model: Accuracy {re_eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save History --\")\n","            # Add a dummy aggregation if history is empty for testing save\n","            if not server_eval_test.aggregation_history:\n","                server_eval_test.aggregation_history.append({'round':0, 'status':'dummy_for_save_test'})\n","            server_eval_test.save_history()\n","        else:\n","            print(\"Global model not initialized on server_eval_test. Skipping Part 3 tests.\")\n","\n","    print(\"\\n--- End of FederatedServer (Part 3) Test ---\")\n","\n","print(\"\\nâœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rp_MOrGFjzv","executionInfo":{"status":"ok","timestamp":1748475823330,"user_tz":-180,"elapsed":813,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"4e9030f3-317b-4f9e-ad67-552b9bb74f1f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\n","Creating new server instance for Part 3 test.\n","\n","-- Testing Global Model Evaluation --\n","Server: Evaluating global model on provided test set (shape: (50, 2))...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Server: Global Model Evaluation - Accuracy: 0.4600, Loss: 0.7000\n","Global model evaluation result (on random data): Accuracy 0.4600\n","\n","-- Testing Save/Load Global Model --\n","Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234344.h5\n","Server: Error loading global model from /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234344.h5: 'Dense' object has no attribute 'input_shape'\n","\n","-- Testing Save History --\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_aggregation_history_20250528_234344.json\n","\n","--- End of FederatedServer (Part 3) Test ---\n","\n","âœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient class (all parts) and FederatedServer class (Parts 1 & 2) should be defined.\n","\n","class FederatedServer:\n","    \"\"\"\n","    Represents the central server in the federated learning system.\n","    Coordinates the training process across multiple clients.\n","    (Includes methods from Part 1 & 2, and adds new methods from Part 3)\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.clients = {}\n","        self.global_model = None\n","        self.global_model_type = None\n","        # For MLP, input_shape will be like (num_features,). For LSTM, (timesteps, num_features) e.g. (1, num_features)\n","        self.global_model_input_shape_for_build = None\n","        self.global_model_num_classes = None\n","        self.aggregation_history = []\n","        # print(\"Federated Server: Initialized.\")\n","\n","    def add_client(self, client):\n","        if not isinstance(client, FederatedClient): return\n","        if client.client_id in self.clients: return\n","        self.clients[client.client_id] = client\n","\n","    def remove_client(self, client_id):\n","        if client_id in self.clients:\n","            del self.clients[client_id]; return True\n","        return False\n","\n","    def initialize_global_model(self, model_type='mlp', input_shape=None, num_classes=None, client_for_shape_details=None):\n","        self.global_model_type = model_type.lower()\n","        final_input_shape_for_build = input_shape # This is the shape passed to model constructor\n","        final_num_classes = num_classes\n","\n","        if final_input_shape_for_build is None or final_num_classes is None:\n","            if client_for_shape_details and client_for_shape_details.data is not None:\n","                temp_feature_columns = None\n","                if hasattr(client_for_shape_details.data, 'columns'):\n","                    temp_data_cols = client_for_shape_details.data.columns.tolist()\n","                    potential_target_col = 'label' if 'label' in temp_data_cols else ('target' if 'target' in temp_data_cols else None)\n","                    temp_df_numeric_cols = client_for_shape_details.data.select_dtypes(include=np.number).columns.tolist()\n","                    if potential_target_col and potential_target_col in temp_df_numeric_cols :\n","                         temp_feature_columns = [col for col in temp_df_numeric_cols if col != potential_target_col]\n","                    elif temp_df_numeric_cols:\n","                         temp_feature_columns = temp_df_numeric_cols\n","\n","                preproc_result = client_for_shape_details.preprocess_data(\n","                    feature_columns=temp_feature_columns,\n","                    target_column=potential_target_col,\n","                    reshape_for_lstm=False # Get basic X_train_sample shape first\n","                )\n","                if preproc_result:\n","                    X_train_sample, _, _, _, preproc_objects = preproc_result\n","                    if final_input_shape_for_build is None:\n","                        # For MLP: (num_features,)\n","                        # For LSTM: (timesteps, num_features) e.g., (1, num_features)\n","                        num_features = X_train_sample.shape[1]\n","                        final_input_shape_for_build = (1, num_features) if self.global_model_type == 'lstm' else (num_features,)\n","                    if final_num_classes is None:\n","                        final_num_classes = preproc_objects['num_classes']\n","\n","        if final_input_shape_for_build is None: final_input_shape_for_build = (1, 10) if self.global_model_type == 'lstm' else (10,)\n","        if final_num_classes is None: final_num_classes = 2\n","\n","        self.global_model_input_shape_for_build = final_input_shape_for_build\n","        self.global_model_num_classes = final_num_classes\n","\n","        temp_client_for_build = FederatedClient(client_id=\"server_model_builder_temp\")\n","        if self.global_model_type == 'lstm':\n","            self.global_model = temp_client_for_build.build_lstm_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","        else: # MLP\n","            self.global_model = temp_client_for_build.build_mlp_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","        del temp_client_for_build\n","\n","        print(f\"Server: Initialized global {self.global_model_type.upper()} model (Build Input Shape: {self.global_model_input_shape_for_build}, Classes: {self.global_model_num_classes}).\")\n","\n","\n","    def federated_averaging(self, client_model_weights_list, client_data_sizes=None):\n","        if not client_model_weights_list: return None\n","        avg_weights = [np.zeros_like(w) for w in client_model_weights_list[0]]\n","        total_data_size = 0\n","        if client_data_sizes:\n","            if len(client_model_weights_list) != len(client_data_sizes): client_data_sizes = None\n","            else: total_data_size = sum(client_data_sizes)\n","\n","        if total_data_size == 0 or client_data_sizes is None:\n","            num_clients_with_weights = len(client_model_weights_list)\n","            for client_weights in client_model_weights_list:\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights / num_clients_with_weights\n","        else:\n","            for idx, client_weights in enumerate(client_model_weights_list):\n","                weight_factor = client_data_sizes[idx] / total_data_size\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights * weight_factor\n","        return avg_weights\n","\n","    def train_round(self, round_number, num_selected_clients=None, epochs_per_client=5, batch_size_per_client=32):\n","        if self.global_model is None or not self.clients: return None\n","        available_client_ids = list(self.clients.keys())\n","        if not available_client_ids: return None\n","        if num_selected_clients is None: num_selected_clients = len(available_client_ids)\n","        selected_client_ids = random.sample(available_client_ids, min(num_selected_clients, len(available_client_ids)))\n","        if not selected_client_ids: return None\n","\n","        print(f\"\\n--- Server: Starting FL Round {round_number} with {len(selected_client_ids)} clients: {selected_client_ids} ---\")\n","        current_global_weights = self.global_model.get_weights()\n","        collected_client_weights, client_data_sizes_for_round, successful_clients_this_round = [], [], []\n","\n","        for client_id in selected_client_ids:\n","            client = self.clients[client_id]\n","\n","            # Ensure client has a model structure compatible with global model\n","            # Global model input shape for build must be used here\n","            if client.model is None or \\\n","               client.model.layers[0].input_shape[1:] != self.global_model_input_shape_for_build or \\\n","               client.model.layers[-1].output_shape[-1] != self.global_model_num_classes:\n","                temp_builder = FederatedClient(client_id=\"temp_model_builder_for_client\")\n","                if self.global_model_type == 'lstm':\n","                    client.model = temp_builder.build_lstm_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","                else:\n","                    client.model = temp_builder.build_mlp_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","                del temp_builder\n","\n","            client.update_model(current_global_weights)\n","\n","            training_result = client.train_local_model(model_type=self.global_model_type, epochs=epochs_per_client, batch_size=batch_size_per_client, verbose=0)\n","            if training_result and 'model_weights' in training_result:\n","                collected_client_weights.append(training_result['model_weights'])\n","                client_data_sizes_for_round.append(training_result['num_samples'])\n","                successful_clients_this_round.append(client_id)\n","                print(f\"Client {client.client_id}: Training successful. Test Acc: {training_result['training_summary']['test_accuracy']:.4f}\")\n","\n","        if not collected_client_weights: print(\"Server: No weights collected.\"); return {'round':round_number, 'status':'failed_no_weights', 'successful_clients':[]}\n","\n","        new_global_weights = self.federated_averaging(collected_client_weights, client_data_sizes_for_round)\n","        if new_global_weights: self.global_model.set_weights(new_global_weights); print(\"Server: Global model updated via FedAvg.\")\n","\n","        round_summary = {'round':round_number, 'status':'completed', 'num_selected':len(selected_client_ids), 'successful_clients':successful_clients_this_round, 'client_data_sizes':client_data_sizes_for_round}\n","        self.aggregation_history.append(round_summary)\n","        return round_summary\n","\n","    def evaluate_global_model(self, X_test_global, y_test_global):\n","        if self.global_model is None: print(\"Server: Global model not init.\"); return None\n","        if X_test_global is None or y_test_global is None or (isinstance(X_test_global, np.ndarray) and X_test_global.size == 0):\n","            print(\"Server: No global test data provided.\"); return None\n","\n","        X_test_to_eval = X_test_global\n","        is_lstm_model = any(isinstance(layer, LSTM) for layer in self.global_model.layers)\n","\n","        if is_lstm_model and len(X_test_to_eval.shape) == 2:\n","             # Expected LSTM input e.g. (1, num_features) from self.global_model_input_shape_for_build\n","             # X_test_to_eval is likely (num_samples, num_features)\n","             if self.global_model_input_shape_for_build and len(self.global_model_input_shape_for_build) == 2:\n","                timesteps = self.global_model_input_shape_for_build[0] # Should be 1\n","                num_features = self.global_model_input_shape_for_build[1]\n","                if X_test_to_eval.shape[1] == num_features: # Check if feature count matches\n","                    X_test_to_eval = X_test_to_eval.reshape(X_test_to_eval.shape[0], timesteps, num_features)\n","                else:\n","                    print(f\"Server: Feature mismatch for LSTM reshaping. Expected {num_features}, got {X_test_to_eval.shape[1]}.\")\n","                    return None # Cannot reshape correctly\n","\n","        # print(f\"Server: Evaluating global model on test set (shape: {X_test_to_eval.shape})...\")\n","        loss, accuracy = self.global_model.evaluate(X_test_to_eval, y_test_global, verbose=0)\n","        y_pred_probs = self.global_model.predict(X_test_to_eval, verbose=0); y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","        report_dict = {}; conf_matrix_list = []\n","        try:\n","            labels = np.union1d(np.unique(y_test_global), np.unique(y_pred_classes))\n","            report_dict = classification_report(y_test_global,y_pred_classes,labels=labels if len(labels)>0 else None,output_dict=True,zero_division=0)\n","            conf_matrix_list = confusion_matrix(y_test_global,y_pred_classes,labels=labels if len(labels)>0 else None).tolist()\n","        except Exception as e: print(f\"Server: Could not gen report/matrix: {e}\")\n","        eval_result = {'timestamp': datetime.now().isoformat(), 'loss': float(loss), 'accuracy': float(accuracy), 'classification_report': report_dict, 'confusion_matrix': conf_matrix_list}\n","        print(f\"Server: Global Model Eval - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n","        return eval_result\n","\n","    def save_global_model(self, path=None):\n","        if self.global_model is None: print(\"Server: No global model.\"); return None\n","        if path is None:\n","            path = os.path.join(MODEL_DIR if 'MODEL_DIR' in globals() else \".\",\n","                                f\"fl_global_{self.global_model_type}_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\")\n","        try: self.global_model.save(path); print(f\"Server: Global model saved to {path}\"); return path\n","        except Exception as e: print(f\"Server: Error saving global model: {e}\"); return None\n","\n","    def load_global_model(self, path):\n","        try:\n","            self.global_model = tf.keras.models.load_model(path)\n","            print(f\"Server: Global model loaded from {path}\")\n","\n","            # Infer model type based on layers\n","            self.global_model_type = 'lstm' if any(isinstance(layer, LSTM) for layer in self.global_model.layers) else 'mlp'\n","\n","            # Infer input shape and num_classes from the loaded model's config\n","            # This is generally more reliable for models saved in .h5 format\n","            config = self.global_model.get_config()\n","\n","            # For input_shape (shape passed to constructor, e.g. (1, num_features) for LSTM or (num_features,) for MLP)\n","            if 'layers' in config and config['layers']:\n","                first_layer_config = config['layers'][0]['config']\n","                if 'batch_input_shape' in first_layer_config:\n","                    # batch_input_shape is (None, timesteps, features) or (None, features)\n","                    self.global_model_input_shape_for_build = first_layer_config['batch_input_shape'][1:]\n","                else: # Fallback if batch_input_shape is not there (e.g. functional API model with Input layer)\n","                    try: # For functional API Input Layer\n","                         self.global_model_input_shape_for_build = self.global_model.input_shape[1:]\n","                    except AttributeError:\n","                         print(\"Server Warning: Could not reliably infer input_shape from loaded model config. May need manual setting.\")\n","                         self.global_model_input_shape_for_build = (1,10) if self.global_model_type == 'lstm' else (10,)\n","\n","\n","                # For num_classes from the last layer\n","                last_layer_config = config['layers'][-1]['config']\n","                if 'units' in last_layer_config:\n","                    self.global_model_num_classes = last_layer_config['units']\n","                else:\n","                    print(\"Server Warning: Could not infer num_classes from loaded model config. Defaulting to 2.\")\n","                    self.global_model_num_classes = 2 # Default\n","            else:\n","                 print(\"Server Warning: Loaded model config has no layers. Using defaults for shape/classes.\")\n","                 self.global_model_input_shape_for_build = (1,10) if self.global_model_type == 'lstm' else (10,)\n","                 self.global_model_num_classes = 2\n","\n","\n","            # Ensure model is compiled if not already\n","            if not self.global_model.optimizer:\n","                print(\"Server: Loaded model optimizer not found. Re-compiling with default Adam.\")\n","                self.global_model.compile(optimizer=Adam(learning_rate=0.001),\n","                                          loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","            print(f\"Server: Inferred from loaded model - Type: {self.global_model_type}, \"\n","                  f\"Build Input Shape: {self.global_model_input_shape_for_build}, Classes: {self.global_model_num_classes}\")\n","            return True\n","        except Exception as e:\n","            print(f\"Server: Error loading global model from {path}: {e}\")\n","            import traceback\n","            traceback.print_exc()\n","            return False\n","\n","    def save_history(self, path=None):\n","        if not self.aggregation_history: print(\"Server: No aggregation history.\"); return None\n","        if path is None:\n","            path = os.path.join(FL_DIR if 'FL_DIR' in globals() else \".\",\n","                                f\"fl_agg_hist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n","        try:\n","            with open(path, 'w') as f: json.dump(self.aggregation_history, f, indent=2)\n","            print(f\"Server: Aggregation history saved to {path}\")\n","            return path\n","        except Exception as e: print(f\"Server: Error saving agg history: {e}\"); return None\n","\n","# --- Test Block for FederatedServer (Part 3: Evaluation & Saving) ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\")\n","\n","    if 'DATA_DIR' not in globals() or not os.path.exists(DATA_DIR) or \\\n","       'MODEL_DIR' not in globals() or not os.path.exists(MODEL_DIR) or \\\n","       'FL_DIR' not in globals() or not os.path.exists(FL_DIR):\n","        print(\"âš ï¸ DATA_DIR, MODEL_DIR or FL_DIR not found. Skipping test. Run Section 1 first.\")\n","    elif 'FederatedClient' not in globals() or 'FederatedServer' not in globals():\n","        print(\"âš ï¸ FederatedClient or FederatedServer class not defined. Run previous sections.\")\n","    else:\n","        server_eval_test = None\n","        if 'server_test_part2' in locals() and isinstance(server_test_part2, FederatedServer) and server_test_part2.global_model:\n","            server_eval_test = server_test_part2\n","            print(\"Using server instance from Part 2 test for Part 3 test.\")\n","        else:\n","            print(\"Creating new server instance for Part 3 test (Part 2 server not found or no model).\")\n","            server_eval_test = FederatedServer()\n","            client_for_init_eval = FederatedClient(client_id=\"init_client_for_eval_test_p3\")\n","            dummy_data_path_eval = os.path.join(DATA_DIR, \"server_client_dummy_data.csv\")\n","            if os.path.exists(dummy_data_path_eval):\n","                client_for_init_eval.load_data(data_path=dummy_data_path_eval)\n","                if client_for_init_eval.data is not None:\n","                     server_eval_test.initialize_global_model(model_type='mlp', client_for_shape_details=client_for_init_eval)\n","                else: # Fallback if client data load failed\n","                     server_eval_test.initialize_global_model(model_type='mlp', input_shape=(2,), num_classes=2)\n","            else: # Fallback if dummy data CSV is missing\n","                print(f\"Dummy data {dummy_data_path_eval} not found, initializing server model with defaults.\")\n","                server_eval_test.initialize_global_model(model_type='mlp', input_shape=(2,), num_classes=2)\n","\n","        if server_eval_test.global_model:\n","            print(\"\\n-- Testing Global Model Evaluation --\")\n","            eval_input_shape_for_build = server_eval_test.global_model_input_shape_for_build\n","            num_eval_samples = 50\n","\n","            if server_eval_test.global_model_type == 'lstm':\n","                # eval_input_shape_for_build is (timesteps, features) e.g. (1, num_features)\n","                X_global_test = np.random.rand(num_eval_samples, eval_input_shape_for_build[0], eval_input_shape_for_build[1])\n","            else: # MLP\n","                # eval_input_shape_for_build is (features,) e.g. (num_features,)\n","                X_global_test = np.random.rand(num_eval_samples, eval_input_shape_for_build[0])\n","\n","            y_global_test = np.random.randint(0, server_eval_test.global_model_num_classes, num_eval_samples)\n","\n","            eval_results = server_eval_test.evaluate_global_model(X_global_test, y_global_test)\n","            if eval_results:\n","                print(f\"Global model evaluation (on random data): Accuracy {eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save/Load Global Model --\")\n","            saved_model_path = server_eval_test.save_global_model()\n","            if saved_model_path and os.path.exists(saved_model_path):\n","                server_new_load_test = FederatedServer()\n","                loaded = server_new_load_test.load_global_model(saved_model_path)\n","                if loaded and server_new_load_test.global_model:\n","                    print(\"Global model loaded into new server instance successfully.\")\n","                    # Re-evaluate to check if loaded model works\n","                    re_eval_results = server_new_load_test.evaluate_global_model(X_global_test, y_global_test)\n","                    if re_eval_results:\n","                         print(f\"Re-evaluation of loaded global model: Accuracy {re_eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save History --\")\n","            if not server_eval_test.aggregation_history:\n","                server_eval_test.aggregation_history.append({'round':0, 'status':'dummy_for_save_test', 'successful_clients':[], 'client_data_sizes':[]})\n","            server_eval_test.save_history()\n","        else:\n","            print(\"Global model not initialized on server_eval_test. Skipping Part 3 tests.\")\n","\n","    print(\"\\n--- End of FederatedServer (Part 3) Test ---\")\n","\n","print(\"\\nâœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qqQfeUnF-gv","executionInfo":{"status":"ok","timestamp":1748475824653,"user_tz":-180,"elapsed":1321,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"64ef13b5-6325-469b-ce8c-bd2b7ba2d906"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\n","Creating new server instance for Part 3 test (Part 2 server not found or no model).\n","Server: Initialized global MLP model (Build Input Shape: (2,), Classes: 2).\n","\n","-- Testing Global Model Evaluation --\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fece7793d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fece7793d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Server: Global Model Eval - Accuracy: 0.5000, Loss: 0.6926\n","Global model evaluation (on random data): Accuracy 0.5000\n","\n","-- Testing Save/Load Global Model --\n","Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234345.h5\n","Server: Global model loaded from /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234345.h5\n","Server: Inferred from loaded model - Type: mlp, Build Input Shape: (2,), Classes: 2\n","Global model loaded into new server instance successfully.\n","Server: Global Model Eval - Accuracy: 0.5000, Loss: 0.6926\n","Re-evaluation of loaded global model: Accuracy 0.5000\n","\n","-- Testing Save History --\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_agg_hist_20250528_234345.json\n","\n","--- End of FederatedServer (Part 3) Test ---\n","\n","âœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient class (all parts) and FederatedServer class (Parts 1 & 2) should be defined.\n","\n","class FederatedServer:\n","    \"\"\"\n","    Represents the central server in the federated learning system.\n","    Coordinates the training process across multiple clients.\n","    (Includes methods from Part 1 & 2, and adds new methods from Part 3)\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.clients = {}\n","        self.global_model = None\n","        self.global_model_type = None\n","        self.global_model_input_shape_for_build = None\n","        self.global_model_num_classes = None\n","        self.aggregation_history = []\n","        # print(\"Federated Server: Initialized.\")\n","\n","    def add_client(self, client):\n","        if not isinstance(client, FederatedClient): return\n","        if client.client_id in self.clients: return\n","        self.clients[client.client_id] = client\n","\n","    def remove_client(self, client_id):\n","        if client_id in self.clients:\n","            del self.clients[client_id]; return True\n","        return False\n","\n","    def initialize_global_model(self, model_type='mlp',\n","                                intended_feature_columns=None,\n","                                intended_target_column=None,\n","                                client_for_shape_details=None,\n","                                default_input_shape=None,\n","                                default_num_classes=2):\n","        self.global_model_type = model_type.lower()\n","        final_input_shape_for_build = default_input_shape\n","        final_num_classes = default_num_classes\n","\n","        if client_for_shape_details and client_for_shape_details.data is not None and \\\n","           intended_feature_columns and intended_target_column:\n","            preproc_result = client_for_shape_details.preprocess_data(\n","                feature_columns=intended_feature_columns,\n","                target_column=intended_target_column,\n","                reshape_for_lstm=False\n","            )\n","            if preproc_result:\n","                X_train_sample, _, _, _, preproc_objects = preproc_result\n","                if X_train_sample is not None and X_train_sample.shape[0] > 0:\n","                    num_features = X_train_sample.shape[1]\n","                    final_input_shape_for_build = (1, num_features) if self.global_model_type == 'lstm' else (num_features,)\n","                    final_num_classes = preproc_objects['num_classes']\n","\n","        if final_input_shape_for_build is None:\n","            final_input_shape_for_build = (1, 10) if self.global_model_type == 'lstm' else (10,)\n","        if final_num_classes is None:\n","            final_num_classes = 2\n","\n","        self.global_model_input_shape_for_build = final_input_shape_for_build\n","        self.global_model_num_classes = final_num_classes\n","\n","        temp_client_for_build = FederatedClient(client_id=\"server_model_builder_temp\")\n","        if self.global_model_type == 'lstm':\n","            self.global_model = temp_client_for_build.build_lstm_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","        else: # MLP\n","            self.global_model = temp_client_for_build.build_mlp_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","        del temp_client_for_build\n","\n","        print(f\"Server: Initialized global {self.global_model_type.upper()} model (Build Input Shape: {self.global_model_input_shape_for_build}, Classes: {self.global_model_num_classes}).\")\n","\n","    def federated_averaging(self, client_model_weights_list, client_data_sizes=None):\n","        if not client_model_weights_list: return None\n","        avg_weights = [np.zeros_like(w) for w in client_model_weights_list[0]]\n","        total_data_size = 0\n","        if client_data_sizes:\n","            if len(client_model_weights_list) != len(client_data_sizes): client_data_sizes = None\n","            else: total_data_size = sum(client_data_sizes)\n","\n","        if total_data_size == 0 or client_data_sizes is None:\n","            num_clients_with_weights = len(client_model_weights_list)\n","            for client_weights in client_model_weights_list:\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights / num_clients_with_weights\n","        else:\n","            for idx, client_weights in enumerate(client_model_weights_list):\n","                weight_factor = client_data_sizes[idx] / total_data_size\n","                for i, layer_weights in enumerate(client_weights): avg_weights[i] += layer_weights * weight_factor\n","        return avg_weights\n","\n","    def train_round(self, round_number, num_selected_clients=None, epochs_per_client=5, batch_size_per_client=32, feature_columns_for_clients=None, target_column_for_clients=None):\n","        if self.global_model is None or not self.clients: return None\n","        available_client_ids = list(self.clients.keys())\n","        if not available_client_ids: return None\n","        if num_selected_clients is None: num_selected_clients = len(available_client_ids)\n","        selected_client_ids = random.sample(available_client_ids, min(num_selected_clients, len(available_client_ids)))\n","        if not selected_client_ids: return None\n","\n","        print(f\"\\n--- Server: Starting FL Round {round_number} with {len(selected_client_ids)} clients: {selected_client_ids} ---\")\n","        current_global_weights = self.global_model.get_weights()\n","        collected_client_weights, client_data_sizes_for_round, successful_clients_this_round = [], [], []\n","\n","        for client_id in selected_client_ids:\n","            client = self.clients[client_id]\n","            rebuild_client_model = False\n","            if client.model is None: rebuild_client_model = True\n","            else:\n","                try:\n","                    client_config = client.model.get_config()\n","                    client_input_shape_from_config = client_config['layers'][0]['config'].get('batch_input_shape')[1:]\n","                    client_output_units_from_config = client_config['layers'][-1]['config'].get('units')\n","                    if client_input_shape_from_config != self.global_model_input_shape_for_build or \\\n","                       client_output_units_from_config != self.global_model_num_classes:\n","                        rebuild_client_model = True\n","                except Exception: rebuild_client_model = True # Rebuild if error checking structure\n","\n","            if rebuild_client_model:\n","                # print(f\"Client {client.client_id}: Rebuilding model structure.\") # Verbose\n","                temp_builder = FederatedClient(client_id=\"temp_builder_round\")\n","                client.model = temp_builder.build_lstm_model(self.global_model_input_shape_for_build, self.global_model_num_classes) if self.global_model_type == 'lstm' \\\n","                    else temp_builder.build_mlp_model(self.global_model_input_shape_for_build, self.global_model_num_classes)\n","                del temp_builder\n","\n","            client.update_model(current_global_weights)\n","            training_result = client.train_local_model(\n","                model_type=self.global_model_type, epochs=epochs_per_client,\n","                batch_size=batch_size_per_client, verbose=0,\n","                feature_columns=feature_columns_for_clients, target_column=target_column_for_clients)\n","            if training_result and 'model_weights' in training_result:\n","                collected_client_weights.append(training_result['model_weights'])\n","                client_data_sizes_for_round.append(training_result['num_samples'])\n","                successful_clients_this_round.append(client_id)\n","                # print(f\"Client {client.client_id}: Train OK. Acc: {training_result['training_summary']['test_accuracy']:.4f}\")\n","        if not collected_client_weights: print(\"Server: No weights collected.\"); return {'round':round_number, 'status':'failed_no_weights', 'successful_clients':[]}\n","        new_global_weights = self.federated_averaging(collected_client_weights, client_data_sizes_for_round)\n","        if new_global_weights: self.global_model.set_weights(new_global_weights); # print(\"Server: Global model updated.\") # Verbose\n","        round_summary = {'round':round_number, 'status':'completed', 'num_selected':len(selected_client_ids), 'successful_clients':successful_clients_this_round, 'client_data_sizes':client_data_sizes_for_round}\n","        self.aggregation_history.append(round_summary)\n","        return round_summary\n","\n","    def evaluate_global_model(self, X_test_global, y_test_global):\n","        if self.global_model is None: print(\"Server: Global model not init.\"); return None\n","        if X_test_global is None or y_test_global is None or (isinstance(X_test_global, np.ndarray) and X_test_global.size == 0):\n","            print(\"Server: No global test data provided.\"); return None\n","        X_test_to_eval = X_test_global\n","        is_lstm_model = any(isinstance(layer, LSTM) for layer in self.global_model.layers)\n","        if is_lstm_model and len(X_test_to_eval.shape) == 2:\n","             if self.global_model_input_shape_for_build and len(self.global_model_input_shape_for_build) == 2: # (timesteps, features)\n","                timesteps, num_features = self.global_model_input_shape_for_build[0], self.global_model_input_shape_for_build[1]\n","                if X_test_to_eval.shape[1] == num_features:\n","                    X_test_to_eval = X_test_to_eval.reshape(X_test_to_eval.shape[0], timesteps, num_features)\n","                else: return None\n","        loss, accuracy = self.global_model.evaluate(X_test_to_eval, y_test_global, verbose=0)\n","        y_pred_probs = self.global_model.predict(X_test_to_eval, verbose=0); y_pred_classes = np.argmax(y_pred_probs, axis=1)\n","        report_dict = {}; conf_matrix_list = []\n","        try:\n","            labels = np.union1d(np.unique(y_test_global), np.unique(y_pred_classes))\n","            report_dict = classification_report(y_test_global,y_pred_classes,labels=labels if len(labels)>0 else None,output_dict=True,zero_division=0)\n","            conf_matrix_list = confusion_matrix(y_test_global,y_pred_classes,labels=labels if len(labels)>0 else None).tolist()\n","        except Exception as e: print(f\"Server: Could not gen report/matrix: {e}\")\n","        eval_result = {'timestamp': datetime.now().isoformat(), 'loss': float(loss), 'accuracy': float(accuracy), 'classification_report': report_dict, 'confusion_matrix': conf_matrix_list}\n","        # print(f\"Server: Global Model Eval - Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\") # Verbose\n","        return eval_result\n","\n","    def save_global_model(self, path=None):\n","        if self.global_model is None: print(\"Server: No global model.\"); return None\n","        if path is None:\n","            path = os.path.join(MODEL_DIR if 'MODEL_DIR' in globals() else \".\", f\"fl_global_{self.global_model_type}_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\")\n","        try: self.global_model.save(path); print(f\"Server: Global model saved to {path}\"); return path\n","        except Exception as e: print(f\"Server: Error saving global model: {e}\"); return None\n","\n","    def load_global_model(self, path):\n","        try:\n","            self.global_model = tf.keras.models.load_model(path)\n","            print(f\"Server: Global model loaded from {path}\")\n","            self.global_model_type = 'lstm' if any(isinstance(layer, LSTM) for layer in self.global_model.layers) else 'mlp'\n","            config = self.global_model.get_config()\n","            if 'layers' in config and config['layers']:\n","                first_layer_config = config['layers'][0]['config']\n","                if 'batch_input_shape' in first_layer_config: self.global_model_input_shape_for_build = first_layer_config['batch_input_shape'][1:]\n","                elif hasattr(self.global_model, 'input_shape') and isinstance(self.global_model.input_shape, tuple) and len(self.global_model.input_shape) > 1: self.global_model_input_shape_for_build = self.global_model.input_shape[1:]\n","                else: self.global_model_input_shape_for_build = None\n","                last_layer_config = config['layers'][-1]['config']\n","                if 'units' in last_layer_config: self.global_model_num_classes = last_layer_config['units']\n","                else: self.global_model_num_classes = None\n","            else: self.global_model_input_shape_for_build = None; self.global_model_num_classes = None;\n","            if not self.global_model.optimizer: self.global_model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","            # print(f\"Server: Loaded model details - Type: {self.global_model_type}, Build Input: {self.global_model_input_shape_for_build}, Classes: {self.global_model_num_classes}\")\n","            return True\n","        except Exception as e: print(f\"Server: Error loading global model from {path}: {e}\"); import traceback; traceback.print_exc(); return False\n","\n","    def save_history(self, path=None):\n","        if not self.aggregation_history: print(\"Server: No aggregation history.\"); return None\n","        if path is None:\n","            path = os.path.join(FL_DIR if 'FL_DIR' in globals() else \".\", f\"fl_agg_hist_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n","        try:\n","            with open(path, 'w') as f: json.dump(self.aggregation_history, f, indent=2)\n","            print(f\"Server: Aggregation history saved to {path}\")\n","            return path\n","        except Exception as e: print(f\"Server: Error saving agg history: {e}\"); return None\n","\n","# --- Test Block for FederatedServer (Part 3: Evaluation & Saving) ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\")\n","\n","    if 'DATA_DIR' not in globals() or not os.path.exists(DATA_DIR) or \\\n","       'MODEL_DIR' not in globals() or not os.path.exists(MODEL_DIR) or \\\n","       'FL_DIR' not in globals() or not os.path.exists(FL_DIR):\n","        print(\"âš ï¸ DATA_DIR, MODEL_DIR or FL_DIR not found. Skipping test. Run Section 1 first.\")\n","    elif 'FederatedClient' not in globals() or 'FederatedServer' not in globals():\n","        print(\"âš ï¸ FederatedClient or FederatedServer class not defined. Run previous sections defining these classes.\")\n","    else:\n","        server_eval_test = None\n","        if 'server_test_part2' in locals() and isinstance(server_test_part2, FederatedServer) and server_test_part2.global_model:\n","            server_eval_test = server_test_part2\n","            print(\"Using server instance from Part 2 test for Part 3 test.\")\n","        else:\n","            print(\"Creating new server instance for Part 3 test.\")\n","            server_eval_test = FederatedServer()\n","            client_for_init_eval = FederatedClient(client_id=\"init_client_for_eval_test_p3\")\n","            dummy_data_path_eval = os.path.join(DATA_DIR, \"server_client_dummy_data.csv\")\n","            dummy_feature_cols_for_init = [f'f{i+1}_numeric' for i in range(2)]\n","            dummy_target_col_for_init = 'target_label'\n","\n","            if not os.path.exists(dummy_data_path_eval):\n","                pd.DataFrame({ # Corrected Indentation for this block\n","                    'f1_numeric': np.random.rand(50), 'f2_numeric': np.random.rand(50),\n","                    'target_label': np.random.choice(['ClassA', 'ClassB'], 50)\n","                }).to_csv(dummy_data_path_eval, index=False)\n","                print(f\"Created dummy data for server test: {dummy_data_path_eval}\")\n","\n","            if os.path.exists(dummy_data_path_eval):\n","                client_for_init_eval.load_data(data_path=dummy_data_path_eval)\n","                if client_for_init_eval.data is not None:\n","                     server_eval_test.initialize_global_model(\n","                         model_type='mlp',\n","                         intended_feature_columns=dummy_feature_cols_for_init,\n","                         intended_target_column=dummy_target_col_for_init,\n","                         client_for_shape_details=client_for_init_eval\n","                     )\n","                else:\n","                     server_eval_test.initialize_global_model(model_type='mlp', default_input_shape=(len(dummy_feature_cols_for_init),), default_num_classes=2)\n","            else:\n","                print(f\"Dummy data {dummy_data_path_eval} not found, initializing server model with defaults.\")\n","                server_eval_test.initialize_global_model(model_type='mlp', default_input_shape=(len(dummy_feature_cols_for_init),), default_num_classes=2)\n","\n","        if server_eval_test.global_model:\n","            print(\"\\n-- Testing Global Model Evaluation --\")\n","            eval_input_shape_for_build = server_eval_test.global_model_input_shape_for_build\n","            num_eval_samples = 50\n","\n","            if server_eval_test.global_model_type == 'lstm':\n","                 X_global_test = np.random.rand(num_eval_samples, eval_input_shape_for_build[0], eval_input_shape_for_build[1])\n","            else: # MLP\n","                 X_global_test = np.random.rand(num_eval_samples, eval_input_shape_for_build[0])\n","            y_global_test = np.random.randint(0, server_eval_test.global_model_num_classes, num_eval_samples)\n","\n","            eval_results = server_eval_test.evaluate_global_model(X_global_test, y_global_test)\n","            if eval_results: print(f\"Global model evaluation (on random data): Accuracy {eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save/Load Global Model --\")\n","            saved_model_path = server_eval_test.save_global_model()\n","            if saved_model_path and os.path.exists(saved_model_path):\n","                server_new_load_test = FederatedServer()\n","                loaded = server_new_load_test.load_global_model(saved_model_path)\n","                if loaded and server_new_load_test.global_model:\n","                    print(\"Global model loaded into new server instance successfully.\")\n","                    re_eval_results = server_new_load_test.evaluate_global_model(X_global_test, y_global_test)\n","                    if re_eval_results: print(f\"Re-evaluation of loaded global model: Accuracy {re_eval_results['accuracy']:.4f}\")\n","\n","            print(\"\\n-- Testing Save History --\")\n","            if not server_eval_test.aggregation_history:\n","                server_eval_test.aggregation_history.append({'round':0, 'status':'dummy_for_save_test'})\n","            server_eval_test.save_history()\n","        else:\n","            print(\"Global model not initialized on server_eval_test. Skipping Part 3 tests.\")\n","    print(\"\\n--- End of FederatedServer (Part 3) Test ---\")\n","\n","print(\"\\nâœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTvT3B92IyP1","executionInfo":{"status":"ok","timestamp":1748475826015,"user_tz":-180,"elapsed":1326,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"a2146c93-67eb-4cc1-8102-ca9c37631f89"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing FederatedServer (Part 3: Evaluation & Saving) ---\n","Creating new server instance for Part 3 test.\n","Server: Initialized global MLP model (Build Input Shape: (2,), Classes: 2).\n","\n","-- Testing Global Model Evaluation --\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Global model evaluation (on random data): Accuracy 0.4400\n","\n","-- Testing Save/Load Global Model --\n","Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234346.h5\n","Server: Global model loaded from /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234346.h5\n","Global model loaded into new server instance successfully.\n","Re-evaluation of loaded global model: Accuracy 0.4400\n","\n","-- Testing Save History --\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_agg_hist_20250528_234347.json\n","\n","--- End of FederatedServer (Part 3) Test ---\n","\n","âœ… Section 7 (FederatedServer Class - Part 3: Evaluation & Saving) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# FederatedClient and FederatedServer classes should be defined from previous sections.\n","\n","def simulate_federated_learning(num_clients=5, num_rounds=5, model_type='mlp',\n","                                data_path=None, feature_columns=None, target_column=None,\n","                                epochs_per_client=5, batch_size_per_client=32,\n","                                clients_per_round=None):\n","    \"\"\"\n","    Simulate a federated learning scenario.\n","    \"\"\"\n","    print(f\"\\n--- Starting Federated Learning Simulation ---\")\n","    print(f\"Config: {num_clients} clients, {num_rounds} rounds, Model: {model_type.upper()}\")\n","    print(f\"Data Path: {data_path if data_path else 'Synthetic Data'}\")\n","\n","    server = FederatedServer()\n","\n","    client_data_list = []\n","    if data_path and os.path.exists(data_path):\n","        print(f\"Loading and partitioning data from: {data_path}\")\n","        try:\n","            if data_path.endswith('.csv'):\n","                full_df = pd.read_csv(data_path, low_memory=False)\n","            elif data_path.endswith(('.json', '.jsonl')):\n","                full_df = pd.read_json(data_path, lines=data_path.endswith('.jsonl'))\n","            else:\n","                raise ValueError(f\"Unsupported data file type: {data_path}\")\n","\n","            if full_df.empty or len(full_df) < num_clients:\n","                print(f\"âš ï¸ Warning: Dataset at {data_path} is empty or too small for {num_clients} clients. Using synthetic data.\")\n","                data_path = None\n","            else:\n","                num_total_samples = len(full_df)\n","                samples_per_client = num_total_samples // num_clients\n","                for i in range(num_clients):\n","                    start_idx = i * samples_per_client\n","                    end_idx = (i + 1) * samples_per_client if i < num_clients - 1 else num_total_samples\n","                    client_df = full_df.iloc[start_idx:end_idx].copy()\n","                    if not client_df.empty:\n","                        client_data_list.append(client_df)\n","\n","                if not client_data_list:\n","                    print(\"âš ï¸ All client data partitions were empty. Falling back to synthetic data.\")\n","                    data_path = None\n","        except Exception as e:\n","            print(f\"âŒ Error loading or partitioning real data: {e}. Falling back to synthetic data.\")\n","            data_path = None\n","\n","    if not client_data_list:\n","        print(\"Generating synthetic data for clients...\")\n","        client_data_list = []\n","        num_synthetic_features = len(feature_columns) if feature_columns and isinstance(feature_columns, list) else 10\n","        cols = feature_columns if feature_columns and isinstance(feature_columns, list) else [f\"feature_{j}\" for j in range(num_synthetic_features)]\n","\n","        for i in range(num_clients):\n","            n_samples = random.randint(200, 500)\n","            X_synthetic = np.random.rand(n_samples, num_synthetic_features)\n","            y_synthetic = np.random.randint(0, 2, size=n_samples)\n","\n","            df_synthetic = pd.DataFrame(X_synthetic, columns=cols)\n","            df_synthetic[target_column if target_column else 'label'] = y_synthetic\n","            client_data_list.append(df_synthetic)\n","\n","    actual_num_clients = len(client_data_list)\n","    if actual_num_clients == 0: print(\"âŒ No data for any client. Aborting.\"); return None\n","\n","    for i in range(actual_num_clients):\n","        client = FederatedClient(client_id=f\"fl_client_{i}\", data=client_data_list[i])\n","        server.add_client(client)\n","\n","    first_client_with_data = next((c for c in server.clients.values() if c.data is not None and not c.data.empty), None)\n","    if not first_client_with_data: print(\"âŒ No client has data for model init. Aborting.\"); return None\n","\n","    server.initialize_global_model(\n","        model_type=model_type,\n","        intended_feature_columns=feature_columns, # Pass intended features for shape inference\n","        intended_target_column=target_column,     # Pass intended target for shape inference\n","        client_for_shape_details=first_client_with_data\n","    )\n","    if server.global_model is None: print(\"âŒ Failed to initialize global model. Aborting.\"); return None\n","\n","    for r in range(1, num_rounds + 1):\n","        server.train_round(\n","            round_number=r,\n","            num_selected_clients=clients_per_round if clients_per_round else actual_num_clients,\n","            epochs_per_client=epochs_per_client,\n","            batch_size_per_client=batch_size_per_client,\n","            feature_columns_for_clients=feature_columns, # Pass to ensure clients use correct features\n","            target_column_for_clients=target_column     # Pass to ensure clients use correct target\n","        )\n","\n","    print(\"\\n--- Performing Final Global Model Evaluation ---\")\n","    all_X_test_scaled, all_y_test = [], []\n","    final_eval_results = None\n","\n","    for client_id, client in server.clients.items():\n","        if client.data is not None and not client.data.empty:\n","            preproc_res = client.preprocess_data(\n","                feature_columns=feature_columns,\n","                target_column=target_column,\n","                reshape_for_lstm=(server.global_model_type == 'lstm')\n","            )\n","            if preproc_res:\n","                _, X_test_client, _, y_test_client, _ = preproc_res\n","                if len(X_test_client) > 0:\n","                    all_X_test_scaled.append(X_test_client)\n","                    all_y_test.append(y_test_client)\n","\n","    if all_X_test_scaled and all_y_test:\n","        try:\n","            global_X_test = np.concatenate(all_X_test_scaled, axis=0)\n","            global_y_test = np.concatenate(all_y_test, axis=0)\n","            if len(global_X_test) > 0:\n","                 final_eval_results = server.evaluate_global_model(global_X_test, global_y_test)\n","            else: print(\"No test data for final global model evaluation after concatenation.\")\n","        except ValueError as ve:\n","            print(f\"Error concatenating client test data for global evaluation: {ve}\")\n","    else:\n","        print(\"No client test data for final global model evaluation.\")\n","\n","    model_save_path = server.save_global_model()\n","    history_save_path = server.save_history()\n","\n","    print(\"\\n--- Federated Learning Simulation Completed ---\")\n","    if final_eval_results: print(f\"Final Global Model Accuracy: {final_eval_results.get('accuracy', 'N/A'):.4f}\")\n","\n","    return {\"num_clients\": actual_num_clients, \"num_rounds\": num_rounds, \"model_type\": model_type, \"final_evaluation\": final_eval_results, \"global_model_path\": model_save_path, \"aggregation_history_path\": history_save_path, \"aggregation_history\": server.aggregation_history}\n","\n","\n","def compare_federated_vs_centralized(data_path, feature_columns, target_column,\n","                                     num_clients=5, num_rounds=5, model_type='mlp',\n","                                     epochs_per_client=5, batch_size_per_client=32,\n","                                     centralized_epochs=20, centralized_batch_size=32):\n","    print(\"\\n--- Comparing Federated Learning vs. Centralized Training ---\")\n","    if not data_path or not os.path.exists(data_path):\n","        print(f\"âŒ Data path '{data_path}' not found. Comparison aborted.\")\n","        return None\n","\n","    print(\"\\n--- Running Federated Learning for Comparison ---\")\n","    fl_sim_summary = simulate_federated_learning(\n","        num_clients=num_clients, num_rounds=num_rounds, model_type=model_type,\n","        data_path=data_path, feature_columns=feature_columns, target_column=target_column,\n","        epochs_per_client=epochs_per_client, batch_size_per_client=batch_size_per_client\n","    )\n","    fl_accuracy = 0.0\n","    if fl_sim_summary and fl_sim_summary.get('final_evaluation') and isinstance(fl_sim_summary['final_evaluation'], dict) :\n","        fl_accuracy = fl_sim_summary['final_evaluation'].get('accuracy', 0.0)\n","\n","    print(\"\\n--- Running Centralized Learning for Comparison ---\")\n","    cen_accuracy = 0.0\n","    try:\n","        full_df_cen = pd.read_csv(data_path, low_memory=False)\n","        full_df_cen.replace([np.inf, -np.inf], np.nan, inplace=True)\n","\n","        # Ensure all specified feature_columns and target_column actually exist before trying to use them\n","        actual_feature_cols_cen = [col for col in feature_columns if col in full_df_cen.columns]\n","        if len(actual_feature_cols_cen) != len(feature_columns):\n","            print(f\"Warning: Not all specified feature_columns found in centralized dataset. Using: {actual_feature_cols_cen}\")\n","        if target_column not in full_df_cen.columns:\n","            raise ValueError(f\"Target column '{target_column}' not found in centralized dataset for comparison.\")\n","\n","        cols_to_check_dropna = actual_feature_cols_cen + [target_column]\n","        full_df_cen.dropna(subset=cols_to_check_dropna, inplace=True)\n","        if full_df_cen.empty: raise ValueError(\"Centralized dataset empty after dropna.\")\n","\n","        X_cen = full_df_cen[actual_feature_cols_cen]\n","        y_cen = full_df_cen[target_column]\n","\n","        X_numeric_cen = X_cen.select_dtypes(include=np.number)\n","        if X_numeric_cen.shape[1] < X_cen.shape[1]:\n","            print(f\"Centralized: Warning - Dropping non-numeric columns: {X_cen.select_dtypes(exclude=np.number).columns.tolist()}\")\n","        X_cen = X_numeric_cen\n","        if X_cen.empty : raise ValueError(\"No numeric features left for centralized training.\")\n","\n","        label_encoder_cen = LabelEncoder(); y_encoded_cen = label_encoder_cen.fit_transform(y_cen)\n","        num_classes_cen = len(label_encoder_cen.classes_)\n","        if num_classes_cen < 2: raise ValueError(\"Centralized training needs at least 2 classes in target.\")\n","\n","        X_train_cen, X_test_cen, y_train_cen, y_test_cen = train_test_split(\n","            X_cen, y_encoded_cen, test_size=0.2, random_state=42, stratify=y_encoded_cen\n","        )\n","\n","        scaler_cen = StandardScaler(); X_train_scaled_cen = scaler_cen.fit_transform(X_train_cen); X_test_scaled_cen = scaler_cen.transform(X_test_cen)\n","\n","        temp_builder_cen = FederatedClient(\"cen_builder_temp\")\n","        input_shape_cen_build = None\n","        if model_type.lower() == 'lstm':\n","            X_train_scaled_cen = X_train_scaled_cen.reshape(X_train_scaled_cen.shape[0], 1, X_train_scaled_cen.shape[1])\n","            X_test_scaled_cen = X_test_scaled_cen.reshape(X_test_scaled_cen.shape[0], 1, X_test_scaled_cen.shape[1])\n","            input_shape_cen_build = (X_train_scaled_cen.shape[1], X_train_scaled_cen.shape[2])\n","            centralized_model = temp_builder_cen.build_lstm_model(input_shape_cen_build, num_classes_cen)\n","        else:\n","            input_shape_cen_build = (X_train_scaled_cen.shape[1],)\n","            centralized_model = temp_builder_cen.build_mlp_model(input_shape_cen_build, num_classes_cen)\n","        del temp_builder_cen\n","\n","        print(f\"Centralized {model_type.upper()} model built. Input: {input_shape_cen_build}, Classes: {num_classes_cen}\")\n","        centralized_model.fit(X_train_scaled_cen, y_train_cen, epochs=centralized_epochs, batch_size=centralized_batch_size, verbose=0,\n","                              validation_data=(X_test_scaled_cen, y_test_cen),\n","                              callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n","\n","        _, cen_accuracy = centralized_model.evaluate(X_test_scaled_cen, y_test_cen, verbose=0)\n","        print(f\"Centralized Model Test Accuracy: {cen_accuracy:.4f}\")\n","    except Exception as e:\n","        print(f\"âŒ Error during centralized training: {e}\"); import traceback; traceback.print_exc()\n","\n","    print(\"\\n--- Comparison Summary ---\")\n","    print(f\"Federated Learning ({model_type.upper()}) Final Global Accuracy: {fl_accuracy:.4f}\")\n","    print(f\"Centralized Learning ({model_type.upper()}) Test Accuracy: {cen_accuracy:.4f}\")\n","\n","    return {\"federated_accuracy\": fl_accuracy, \"centralized_accuracy\": cen_accuracy}\n","\n","# --- Test Block for Simulation Functions ---\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Testing Simulation Functions ---\")\n","    if 'DATA_DIR' not in globals() or 'MODEL_DIR' not in globals() or 'FL_DIR' not in globals():\n","        print(\"âš ï¸ DATA_DIR, MODEL_DIR, or FL_DIR not defined. Skipping. Run Section 1 first.\")\n","    else:\n","        REAL_DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\"\n","        REAL_FEATURE_COLUMNS = [\n","            'arp.hw.size', 'http.content_length', 'http.response', 'http.tls_port',\n","            'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst',\n","            'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags.ack',\n","            'tcp.len', 'udp.stream', 'udp.time_delta', 'dns.qry.qu', 'dns.qry.type',\n","            'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in',\n","            'mqtt.conflag.cleansess', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as',\n","            'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id'\n","        ]\n","        REAL_TARGET_COLUMN = 'Attack_label'\n","\n","        if os.path.exists(REAL_DATASET_PATH):\n","            print(f\"\\n--- Test 1: Running simulate_federated_learning with '{REAL_DATASET_PATH}' ---\")\n","            fl_sim_results = simulate_federated_learning(\n","                num_clients=2, num_rounds=1, model_type='mlp',\n","                data_path=REAL_DATASET_PATH, feature_columns=REAL_FEATURE_COLUMNS, target_column=REAL_TARGET_COLUMN,\n","                epochs_per_client=1, batch_size_per_client=32, clients_per_round=2)\n","            if fl_sim_results: print(\"FL simulation with real data completed.\")\n","        else:\n","            print(f\"âš ï¸ Dataset {REAL_DATASET_PATH} not found. Running FL with synthetic data.\")\n","            simulate_federated_learning(num_clients=2, num_rounds=1, model_type='mlp', epochs_per_client=1,\n","                                        feature_columns=['f1','f2','f3'], target_column='label') # Pass example feature/target for synthetic\n","\n","        print(f\"\\n--- Test 2: Running compare_federated_vs_centralized (using synthetic data for test robustness) ---\")\n","        synthetic_compare_path = os.path.join(DATA_DIR, \"compare_synthetic_data.csv\")\n","        synthetic_features = [f'synth_feat_{k}' for k in range(5)]\n","        pd.DataFrame(\n","            np.random.rand(200, len(synthetic_features)), columns=synthetic_features\n","        ).assign(target=np.random.randint(0,2,200)).to_csv(synthetic_compare_path, index=False)\n","\n","        compare_results = compare_federated_vs_centralized(\n","            data_path=synthetic_compare_path, feature_columns=synthetic_features, target_column='target',\n","            num_clients=2, num_rounds=1, model_type='mlp', epochs_per_client=1, centralized_epochs=2)\n","        if compare_results: print(\"Comparison simulation completed.\")\n","    print(\"\\n--- End of Simulation Functions Test ---\")\n","\n","print(\"\\nâœ… Section 8 (Federated Learning - Simulation Functions) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgpkWgjNHC80","executionInfo":{"status":"ok","timestamp":1748475842171,"user_tz":-180,"elapsed":16103,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"a8dfd053-4eee-40bb-8175-1e4314ce8d35"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Testing Simulation Functions ---\n","âš ï¸ Dataset /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv not found. Running FL with synthetic data.\n","\n","--- Starting Federated Learning Simulation ---\n","Config: 2 clients, 1 rounds, Model: MLP\n","Data Path: Synthetic Data\n","Generating synthetic data for clients...\n","Server: Initialized global MLP model (Build Input Shape: (3,), Classes: 2).\n","\n","--- Server: Starting FL Round 1 with 2 clients: ['fl_client_1', 'fl_client_0'] ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Performing Final Global Model Evaluation ---\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234353.h5\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_agg_hist_20250528_234353.json\n","\n","--- Federated Learning Simulation Completed ---\n","Final Global Model Accuracy: 0.4872\n","\n","--- Test 2: Running compare_federated_vs_centralized (using synthetic data for test robustness) ---\n","\n","--- Comparing Federated Learning vs. Centralized Training ---\n","\n","--- Running Federated Learning for Comparison ---\n","\n","--- Starting Federated Learning Simulation ---\n","Config: 2 clients, 1 rounds, Model: MLP\n","Data Path: /content/federated_ids_ai_project/data/compare_synthetic_data.csv\n","Loading and partitioning data from: /content/federated_ids_ai_project/data/compare_synthetic_data.csv\n","Server: Initialized global MLP model (Build Input Shape: (5,), Classes: 2).\n","\n","--- Server: Starting FL Round 1 with 2 clients: ['fl_client_1', 'fl_client_0'] ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Performing Final Global Model Evaluation ---\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234359.h5\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_agg_hist_20250528_234359.json\n","\n","--- Federated Learning Simulation Completed ---\n","Final Global Model Accuracy: 0.5250\n","\n","--- Running Centralized Learning for Comparison ---\n","Centralized MLP model built. Input: (5,), Classes: 2\n","Centralized Model Test Accuracy: 0.5000\n","\n","--- Comparison Summary ---\n","Federated Learning (MLP) Final Global Accuracy: 0.5250\n","Centralized Learning (MLP) Test Accuracy: 0.5000\n","Comparison simulation completed.\n","\n","--- End of Simulation Functions Test ---\n","\n","âœ… Section 8 (Federated Learning - Simulation Functions) is ready.\n"]}]},{"cell_type":"code","source":["# Imports from Section 1 should still be in effect.\n","# All classes (FederatedClient, FederatedServer) and simulation functions\n","# (simulate_federated_learning, compare_federated_vs_centralized) should be defined\n","# from previous sections.\n","# Global directories (BASE_DIR, DATA_DIR, MODEL_DIR, FL_DIR) should also be defined.\n","\n","def main():\n","    \"\"\"\n","    Main function to initialize and run the IDS system for federated learning.\n","    Handles argument parsing (simulated for Colab) and orchestrates the simulation.\n","    \"\"\"\n","    class SimulatedArgs:\n","        def __init__(self):\n","            self.data = \"/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\"\n","            self.feature_columns = [\n","                'arp.hw.size', 'http.content_length', 'http.response', 'http.tls_port',\n","                'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst',\n","                'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags.ack',\n","                'tcp.len', 'udp.stream', 'udp.time_delta', 'dns.qry.qu', 'dns.qry.type',\n","                'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in',\n","                'mqtt.conflag.cleansess', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as',\n","                'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id'\n","            ]\n","            self.target_column = 'Attack_label'\n","            self.clients = 3\n","            self.rounds = 2\n","            self.epochs = 2\n","            self.batch_size = 32\n","            self.model = \"mlp\"\n","            self.clients_per_round = 2\n","            self.centralized_epochs = 5\n","            self.compare = False\n","\n","    args = SimulatedArgs()\n","\n","    print(\"--- Federated Learning System Orchestration ---\")\n","    print(f\"Configuration: Dataset Path='{args.data}'\")\n","    print(f\"               Clients={args.clients}, Rounds={args.rounds}, Epochs/Client={args.epochs}, Model='{args.model.upper()}'\")\n","    if args.compare:\n","        print(\"Mode: Comparing Federated vs. Centralized Learning\")\n","    else:\n","        print(\"Mode: Running Federated Learning Simulation Only\")\n","\n","    if args.data and not os.path.exists(args.data): # Check if args.data is not None before os.path.exists\n","        print(f\"âš ï¸ WARNING: Dataset not found at '{args.data}'. \"\n","              \"Simulation will proceed with internally generated SYNTHETIC data for clients.\")\n","    elif args.data:\n","        print(f\"âœ… Using dataset: {args.data}\")\n","    else: # args.data is None\n","        print(f\"â„¹ï¸ No dataset path provided. Simulation will use SYNTHETIC data.\")\n","\n","\n","    if args.compare:\n","        results = compare_federated_vs_centralized(\n","            data_path=args.data,\n","            feature_columns=args.feature_columns,\n","            target_column=args.target_column,\n","            num_clients=args.clients,\n","            num_rounds=args.rounds,\n","            model_type=args.model,\n","            epochs_per_client=args.epochs,\n","            batch_size_per_client=args.batch_size,\n","            centralized_epochs=args.centralized_epochs,\n","        )\n","    else:\n","        results = simulate_federated_learning(\n","            num_clients=args.clients,\n","            num_rounds=args.rounds,\n","            model_type=args.model,\n","            data_path=args.data,\n","            feature_columns=args.feature_columns,\n","            target_column=args.target_column,\n","            epochs_per_client=args.epochs,\n","            batch_size_per_client=args.batch_size,\n","            clients_per_round=args.clients_per_round\n","        )\n","\n","    if results:\n","        results_filename = f\"fl_results_{args.model}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n","        results_path = os.path.join(FL_DIR, results_filename)\n","        try:\n","            with open(results_path, 'w') as f:\n","                class NpEncoder(json.JSONEncoder):\n","                    def default(self, obj):\n","                        if isinstance(obj, np.integer): return int(obj)\n","                        if isinstance(obj, np.floating): return float(obj)\n","                        if isinstance(obj, np.ndarray): return obj.tolist()\n","                        return super(NpEncoder, self).default(obj)\n","                json.dump(results, f, indent=2, cls=NpEncoder)\n","            print(f\"\\nðŸ“Š Comprehensive simulation results saved to: {results_path}\")\n","        except Exception as e:\n","            print(f\"âŒ Error saving comprehensive results: {e}\")\n","    else:\n","        print(\"\\nâ„¹ï¸ Simulation did not produce results to save (possibly due to an earlier error or empty data).\")\n","\n","    print(\"\\nðŸ Federated Learning Main Execution Finished.\")\n","\n","if __name__ == \"__main__\" and 'google.colab' in sys.modules:\n","    print(\"\\n--- Running main() for Federated Learning Demonstration ---\")\n","    essential_items = [\n","        'FederatedClient', 'FederatedServer',\n","        'simulate_federated_learning', 'compare_federated_vs_centralized',\n","        'BASE_DIR', 'DATA_DIR', 'MODEL_DIR', 'FL_DIR'\n","    ]\n","    all_defined = True\n","    for item_name in essential_items:\n","        if item_name not in globals():\n","            print(f\"ðŸ”´ CRITICAL ERROR for main(): Required item '{item_name}' is not defined. \"\n","                  \"Ensure all previous code sections (1-8) ran successfully.\")\n","            all_defined = False\n","            break\n","\n","    if all_defined:\n","        main()\n","    else:\n","        print(\"\\nâŒ Main function execution aborted due to missing definitions.\")\n","\n","print(\"\\nâœ… Section 9 (Federated Learning - Main Execution Block) is ready.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gya9TMQdH_S0","executionInfo":{"status":"ok","timestamp":1748475853734,"user_tz":-180,"elapsed":11537,"user":{"displayName":"Graduation project CIC 2025","userId":"06762630713984150762"}},"outputId":"9fc17823-416b-4ecc-ccf2-416c59509bde"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Running main() for Federated Learning Demonstration ---\n","--- Federated Learning System Orchestration ---\n","Configuration: Dataset Path='/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv'\n","               Clients=3, Rounds=2, Epochs/Client=2, Model='MLP'\n","Mode: Running Federated Learning Simulation Only\n","âš ï¸ WARNING: Dataset not found at '/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv'. Simulation will proceed with internally generated SYNTHETIC data for clients.\n","\n","--- Starting Federated Learning Simulation ---\n","Config: 3 clients, 2 rounds, Model: MLP\n","Data Path: /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\n","Generating synthetic data for clients...\n","Server: Initialized global MLP model (Build Input Shape: (27,), Classes: 2).\n","\n","--- Server: Starting FL Round 1 with 2 clients: ['fl_client_1', 'fl_client_0'] ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Server: Starting FL Round 2 with 2 clients: ['fl_client_2', 'fl_client_1'] ---\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Performing Final Global Model Evaluation ---\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Server: Global model saved to /content/federated_ids_ai_project/models/fl_global_mlp_model_20250528_234414.h5\n","Server: Aggregation history saved to /content/federated_ids_ai_project/federated_outputs/fl_agg_hist_20250528_234414.json\n","\n","--- Federated Learning Simulation Completed ---\n","Final Global Model Accuracy: 0.4583\n","\n","ðŸ“Š Comprehensive simulation results saved to: /content/federated_ids_ai_project/federated_outputs/fl_results_mlp_20250528_234414.json\n","\n","ðŸ Federated Learning Main Execution Finished.\n","\n","âœ… Section 9 (Federated Learning - Main Execution Block) is ready.\n"]}]}]}